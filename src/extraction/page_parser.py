"""
é¡µé¢è§£æå™¨

è´Ÿè´£æ‰€æœ‰é¡µé¢è§£æå·¥ä½œï¼ŒåŒ…æ‹¬ï¼š
- è§£æèŒä½åˆ—è¡¨é¡µé¢ï¼Œæå–èŒä½åŸºæœ¬ä¿¡æ¯
- è§£æèŒä½è¯¦æƒ…é¡µé¢ï¼Œæå–è¯¦ç»†ä¿¡æ¯
- é€šè¿‡ç‚¹å‡»æ“ä½œè·å–èŒä½è¯¦æƒ…é¡µURL
- é¡µé¢ç»“æ„åˆ†æå’Œè°ƒè¯•
"""

import time
import logging
import random
from datetime import datetime
from typing import Dict, List, Optional, Any
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from ..core.exceptions import PageParseError


class PageParser:
    """é¡µé¢è§£æå™¨"""
    
    def __init__(self, config: dict):
        """
        åˆå§‹åŒ–é¡µé¢è§£æå™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.selectors = config.get('selectors', {})
        self.search_selectors = self.selectors.get('search_page', {})
        self.detail_selectors = self.selectors.get('job_detail', {})
        self.logger = logging.getLogger(__name__)
    
    def parse_job_list(self, driver: webdriver.Chrome, max_results: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        è§£æèŒä½åˆ—è¡¨é¡µé¢
        
        Args:
            driver: WebDriverå®ä¾‹
            max_results: æœ€å¤§ç»“æœæ•°é‡
            
        Returns:
            èŒä½ä¿¡æ¯åˆ—è¡¨
            
        Raises:
            PageParseError: é¡µé¢è§£æå¤±è´¥
        """
        try:
            self.logger.info("ğŸ“Š å¼€å§‹è§£æèŒä½åˆ—è¡¨é¡µé¢")
            
            # ç­‰å¾…é¡µé¢ç¨³å®š
            self._wait_for_page_stable(driver)
            
            # è·å–èŒä½åˆ—è¡¨å…ƒç´ 
            job_elements = self._get_job_elements(driver)
            
            if not job_elements:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°èŒä½åˆ—è¡¨å…ƒç´ ")
                self.logger.warning("ğŸ’¡ æç¤º: å»ºè®®äººå·¥æ£€æŸ¥é¡µé¢ç»“æ„ï¼Œå¯èƒ½éœ€è¦æ›´æ–°é€‰æ‹©å™¨")
                return []
            
            self.logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(job_elements)} ä¸ªèŒä½å…ƒç´ ")
            
            # è§£ææ¯ä¸ªèŒä½
            jobs = []
            processed_count = 0
            
            self.logger.info(f"ğŸ”„ å¼€å§‹é€ä¸ªè§£æèŒä½å…ƒç´ ...")
            
            for i, job_element in enumerate(job_elements, 1):
                self.logger.info(f"ğŸ¯ æ­£åœ¨å¤„ç†ç¬¬ {i}/{len(job_elements)} ä¸ªèŒä½å…ƒç´ ")
                
                if max_results and processed_count >= max_results:
                    self.logger.info(f"ğŸ“Š å·²è¾¾åˆ°æœ€å¤§ç»“æœæ•°é‡é™åˆ¶: {max_results}")
                    break
                
                try:
                    self.logger.debug(f"ğŸ“ å¼€å§‹è§£æèŒä½å…ƒç´  {i}...")
                    job_data = self._parse_job_element(job_element)
                    self.logger.debug(f"ğŸ“ èŒä½å…ƒç´  {i} è§£æå®Œæˆ")
                    
                    if job_data:
                        jobs.append(job_data)
                        processed_count += 1
                        
                        self.logger.info(
                            f"âœ… èŒä½ {processed_count}: {job_data.get('title', 'æœªçŸ¥')} - "
                            f"{job_data.get('company', 'æœªçŸ¥')} - {job_data.get('salary', 'é¢è®®')}"
                        )
                    else:
                        self.logger.warning(f"âš ï¸ èŒä½å…ƒç´  {i} è§£æç»“æœä¸ºç©º")
                    
                except Exception as e:
                    self.logger.error(f"âŒ è§£æèŒä½ {i} æ—¶å‡ºé”™: {e}")
                    import traceback
                    self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                    continue
            
            self.logger.info(f"âœ… èŒä½åˆ—è¡¨è§£æå®Œæˆï¼Œå…±è§£æ {len(jobs)} ä¸ªèŒä½")
            return jobs
            
        except Exception as e:
            self.logger.error(f"âŒ è§£æèŒä½åˆ—è¡¨å¤±è´¥: {e}")
            raise PageParseError(f"è§£æèŒä½åˆ—è¡¨å¤±è´¥: {e}")
    
    def _wait_for_page_stable(self, driver: webdriver.Chrome, timeout: int = 10) -> None:
        """
        ç­‰å¾…é¡µé¢ç¨³å®šåŠ è½½ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        Args:
            driver: WebDriverå®ä¾‹
            timeout: è¶…æ—¶æ—¶é—´
        """
        try:
            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            WebDriverWait(driver, timeout).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )
            
            # ä¼˜åŒ–ï¼šå‡å°‘é¢å¤–ç­‰å¾…æ—¶é—´
            time.sleep(0.5)  # ä»2ç§’å‡å°‘åˆ°0.5ç§’
            
            self.logger.debug("é¡µé¢å·²ç¨³å®šåŠ è½½")
            
        except TimeoutException:
            self.logger.warning("é¡µé¢åŠ è½½è¶…æ—¶ï¼Œç»§ç»­å°è¯•è§£æ")
    
    def _get_job_elements(self, driver: webdriver.Chrome) -> List:
        """
        è·å–èŒä½åˆ—è¡¨å…ƒç´ 
        
        Args:
            driver: WebDriverå®ä¾‹
            
        Returns:
            èŒä½å…ƒç´ åˆ—è¡¨
        """
        job_list_selector = self.search_selectors.get('job_list', '.job-list-item')
        
        try:
            # å¦‚æœjob_list_selectoræ˜¯å®¹å™¨é€‰æ‹©å™¨ï¼ˆå¦‚.joblistï¼‰ï¼Œéœ€è¦æŸ¥æ‰¾å…¶å­å…ƒç´ 
            if job_list_selector == '.joblist':
                # åœ¨.joblistå®¹å™¨å†…æŸ¥æ‰¾èŒä½é¡¹
                job_item_selectors = [
                    '.joblist .joblist-item',
                    '.joblist > div',
                    '.joblist li',
                    '.joblist [data-jobid]',
                    '.joblist .job-item'
                ]
                
                for selector in job_item_selectors:
                    try:
                        elements = driver.find_elements(By.CSS_SELECTOR, selector)
                        if elements:
                            self.logger.debug(f"åœ¨å®¹å™¨å†…æ‰¾åˆ°èŒä½é¡¹: {selector} (æ•°é‡: {len(elements)})")
                            return elements
                    except:
                        continue
                
                # å¦‚æœæ‰¾ä¸åˆ°å­å…ƒç´ ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨å®¹å™¨çš„ç›´æ¥å­å…ƒç´ 
                try:
                    container = driver.find_element(By.CSS_SELECTOR, job_list_selector)
                    # è·å–å®¹å™¨çš„æ‰€æœ‰ç›´æ¥å­å…ƒç´ 
                    job_elements = container.find_elements(By.XPATH, "./*")
                    if job_elements:
                        self.logger.debug(f"ä½¿ç”¨å®¹å™¨ç›´æ¥å­å…ƒç´ ï¼Œæ‰¾åˆ° {len(job_elements)} ä¸ª")
                        return job_elements
                except:
                    pass
            else:
                # ç›´æ¥ä½¿ç”¨é…ç½®çš„é€‰æ‹©å™¨
                job_elements = driver.find_elements(By.CSS_SELECTOR, job_list_selector)
                if job_elements:
                    self.logger.debug(f"ä½¿ç”¨é€‰æ‹©å™¨ '{job_list_selector}' æ‰¾åˆ° {len(job_elements)} ä¸ªå…ƒç´ ")
                    return job_elements
            
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„é€‰æ‹©å™¨
            alternative_selectors = [
                '.job-item',
                '.position-item',
                '.search-result-item',
                '.list-item',
                '[data-testid*="job"]',
                '.joblist-item',
                '.job-box',
                '.position-box'
            ]
            
            for selector in alternative_selectors:
                try:
                    elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        self.logger.info(f"ä½¿ç”¨å¤‡ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
                        return elements
                except:
                    continue
            
            return []
            
        except Exception as e:
            self.logger.error(f"è·å–èŒä½å…ƒç´ å¤±è´¥: {e}")
            return []
    
    def _parse_job_element(self, job_element) -> Optional[Dict[str, Any]]:
        """
        è§£æå•ä¸ªèŒä½å…ƒç´ 
        
        Args:
            job_element: èŒä½å…ƒç´ 
            
        Returns:
            èŒä½æ•°æ®å­—å…¸
        """
        self.logger.debug("ğŸ” å¼€å§‹è§£æèŒä½å…ƒç´ ...")
        
        job_data = {
            'extracted_at': time.strftime('%Y-%m-%d %H:%M:%S'),
            'source': 'qiancheng'
        }
        
        try:
            # èŒä½æ ‡é¢˜å’Œé“¾æ¥
            self.logger.debug("ğŸ“ æå–èŒä½æ ‡é¢˜å’Œé“¾æ¥...")
            title_info = self._extract_title_and_url(job_element)
            job_data.update(title_info)
            self.logger.debug(f"ğŸ“ æ ‡é¢˜æå–å®Œæˆ: {title_info.get('title', 'æœªçŸ¥')}")
            
            # å…¬å¸åç§°
            self.logger.debug("ğŸ¢ æå–å…¬å¸åç§°...")
            job_data['company'] = self._extract_text_by_selector(
                job_element,
                self.search_selectors.get('company_name', '.cname'),
                default="æœªçŸ¥å…¬å¸"
            )
            self.logger.debug(f"ğŸ¢ å…¬å¸åç§°: {job_data['company']}")
            
            # è–ªèµ„
            self.logger.debug("ğŸ’° æå–è–ªèµ„ä¿¡æ¯...")
            job_data['salary'] = self._extract_text_by_selector(
                job_element,
                self.search_selectors.get('salary', '.sal'),
                default="è–ªèµ„é¢è®®"
            )
            self.logger.debug(f"ğŸ’° è–ªèµ„: {job_data['salary']}")
            
            # åœ°ç‚¹
            self.logger.debug("ğŸ“ æå–åœ°ç‚¹ä¿¡æ¯...")
            job_data['location'] = self._extract_text_by_selector(
                job_element,
                self.search_selectors.get('location', '.area'),
                default="æœªçŸ¥åœ°ç‚¹"
            )
            self.logger.debug(f"ğŸ“ åœ°ç‚¹: {job_data['location']}")
            
            # ç»éªŒè¦æ±‚
            self.logger.debug("ğŸ“ æå–ç»éªŒè¦æ±‚...")
            job_data['experience'] = self._extract_text_by_selector(
                job_element,
                self.search_selectors.get('experience', '.experience'),
                default="ç»éªŒä¸é™"
            )
            self.logger.debug(f"ğŸ“ ç»éªŒ: {job_data['experience']}")
            
            # å­¦å†è¦æ±‚
            self.logger.debug("ğŸ“š æå–å­¦å†è¦æ±‚...")
            job_data['education'] = self._extract_text_by_selector(
                job_element,
                self.search_selectors.get('education', '.education'),
                default="å­¦å†ä¸é™"
            )
            self.logger.debug(f"ğŸ“š å­¦å†: {job_data['education']}")
            
            # æå–é¢å¤–ä¿¡æ¯
            self.logger.debug("â„¹ï¸ æå–é¢å¤–ä¿¡æ¯...")
            extra_info = self._extract_extra_info(job_element)
            job_data.update(extra_info)
            self.logger.debug("â„¹ï¸ é¢å¤–ä¿¡æ¯æå–å®Œæˆ")
            
            self.logger.debug("âœ… èŒä½å…ƒç´ è§£æå®Œæˆ")
            return job_data
            
        except Exception as e:
            self.logger.error(f"âŒ è§£æèŒä½å…ƒç´ å¤±è´¥: {e}")
            import traceback
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return None
    
    def _extract_title_and_url(self, job_element) -> Dict[str, str]:
        """
        æå–èŒä½æ ‡é¢˜å’Œé“¾æ¥ï¼ˆé‡æ„ç‰ˆæœ¬ - ç®€åŒ–é€»è¾‘ï¼‰
        
        Args:
            job_element: èŒä½å…ƒç´ 
            
        Returns:
            åŒ…å«titleã€urlå’Œneeds_click_extractionçš„å­—å…¸
        """
        try:
            # ä»é…ç½®ä¸­è·å–èŒä½æ ‡é¢˜é€‰æ‹©å™¨
            title_selector = self.search_selectors.get('job_title', '.jname a')
            
            # å°è¯•æå–èŒä½æ ‡é¢˜
            job_title = None
            try:
                # é¦–å…ˆå°è¯•é…ç½®çš„é€‰æ‹©å™¨
                title_element = job_element.find_element(By.CSS_SELECTOR, title_selector)
                job_title = title_element.text.strip()
                
                # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œå°è¯•titleå±æ€§
                if not job_title:
                    job_title = title_element.get_attribute('title')
                    if job_title:
                        job_title = job_title.strip()
                
                if job_title:
                    self.logger.debug(f"é€šè¿‡é…ç½®é€‰æ‹©å™¨æ‰¾åˆ°èŒä½æ ‡é¢˜: {job_title}")
                    # æ‰¾åˆ°æ ‡é¢˜å°±ç«‹å³è¿”å›ï¼Œä¸å†æŸ¥æ‰¾URL
                    return {
                        'title': job_title,
                        'url': "",
                        'needs_click_extraction': True
                    }
                    
            except Exception as e:
                self.logger.debug(f"é…ç½®é€‰æ‹©å™¨ '{title_selector}' æœªæ‰¾åˆ°å…ƒç´ : {e}")
            
            # å¦‚æœé…ç½®é€‰æ‹©å™¨å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨é€‰æ‹©å™¨
            backup_selectors = ['.jname', '.job-name', '.position-title']
            for selector in backup_selectors:
                try:
                    title_element = job_element.find_element(By.CSS_SELECTOR, selector)
                    job_title = title_element.text.strip()
                    
                    if not job_title:
                        job_title = title_element.get_attribute('title')
                        if job_title:
                            job_title = job_title.strip()
                    
                    if job_title:
                        self.logger.debug(f"é€šè¿‡å¤‡ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ°èŒä½æ ‡é¢˜: {job_title}")
                        return {
                            'title': job_title,
                            'url': "",
                            'needs_click_extraction': True
                        }
                        
                except Exception:
                    continue
            
            # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›é»˜è®¤å€¼
            self.logger.warning("æœªæ‰¾åˆ°èŒä½æ ‡é¢˜")
            return {
                'title': "æœªçŸ¥èŒä½",
                'url': "",
                'needs_click_extraction': False
            }
                
        except Exception as e:
            self.logger.warning(f"æå–èŒä½æ ‡é¢˜å¤±è´¥: {e}")
            return {
                'title': "æœªçŸ¥èŒä½",
                'url': "",
                'needs_click_extraction': False
            }
    
    def _extract_text_by_selector(self, parent_element, selector: str, default: str = "") -> str:
        """
        é€šè¿‡é€‰æ‹©å™¨æå–æ–‡æœ¬ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        Args:
            parent_element: çˆ¶å…ƒç´ 
            selector: CSSé€‰æ‹©å™¨
            default: é»˜è®¤å€¼
            
        Returns:
            æå–çš„æ–‡æœ¬
        """
        try:
            # æ·»åŠ è¶…æ—¶æœºåˆ¶ï¼Œé¿å…é•¿æ—¶é—´ç­‰å¾…
            element = parent_element.find_element(By.CSS_SELECTOR, selector)
            text = element.text.strip()
            return text if text else default
        except Exception:
            # å¿«é€Ÿå¤±è´¥ï¼Œä¸è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
            return default
    
    def _extract_extra_info(self, job_element) -> Dict[str, Any]:
        """
        æå–é¢å¤–ä¿¡æ¯
        
        Args:
            job_element: èŒä½å…ƒç´ 
            
        Returns:
            é¢å¤–ä¿¡æ¯å­—å…¸
        """
        extra_info = {}
        
        try:
            # å°è¯•æå–å‘å¸ƒæ—¶é—´
            time_selectors = ['.publish-time', '.update-time', '.time', '[data-time]']
            for selector in time_selectors:
                try:
                    time_element = job_element.find_element(By.CSS_SELECTOR, selector)
                    extra_info['publish_time'] = time_element.text.strip()
                    break
                except:
                    continue
            
            # å°è¯•æå–å…¬å¸è§„æ¨¡
            scale_selectors = ['.company-scale', '.company-size', '.scale']
            for selector in scale_selectors:
                try:
                    scale_element = job_element.find_element(By.CSS_SELECTOR, selector)
                    extra_info['company_scale'] = scale_element.text.strip()
                    break
                except:
                    continue
            
            # å°è¯•æå–è¡Œä¸šä¿¡æ¯
            industry_selectors = ['.industry', '.company-industry', '.business']
            for selector in industry_selectors:
                try:
                    industry_element = job_element.find_element(By.CSS_SELECTOR, selector)
                    extra_info['industry'] = industry_element.text.strip()
                    break
                except:
                    continue
            
        except Exception as e:
            self.logger.debug(f"æå–é¢å¤–ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        
        return extra_info
    
    def parse_job_detail(self, driver: webdriver.Chrome, job_url: str) -> Optional[Dict[str, Any]]:
        """
        è§£æèŒä½è¯¦æƒ…é¡µé¢
        
        Args:
            driver: WebDriverå®ä¾‹
            job_url: èŒä½è¯¦æƒ…URL
            
        Returns:
            èŒä½è¯¦æƒ…æ•°æ®
        """
        try:
            self.logger.info(f"ğŸ“„ è§£æèŒä½è¯¦æƒ…: {job_url}")
            
            # æ ¹æ®æ¨¡å¼è°ƒæ•´è¯¦æƒ…é¡µç­‰å¾…æ—¶é—´
            config_mode = getattr(self, 'config', {}).get('mode', {})
            is_debug_mode = config_mode.get('development', False) or config_mode.get('debug', False)
            
            if is_debug_mode:
                # å¼€å‘æ¨¡å¼ï¼šå¿«é€Ÿç­‰å¾…
                self._wait_for_page_stable(driver, timeout=3)  # å¼€å‘æ¨¡å¼3ç§’
            else:
                # ç”Ÿäº§æ¨¡å¼ï¼šæ­£å¸¸ç­‰å¾…
                self._wait_for_page_stable(driver, timeout=6)  # ç”Ÿäº§æ¨¡å¼6ç§’
            
            # æ£€æŸ¥é¡µé¢æ˜¯å¦æ­£å¸¸åŠ è½½
            page_title = driver.title
            if not page_title or '404' in page_title or 'error' in page_title.lower():
                self.logger.warning(f"é¡µé¢å¯èƒ½æœªæ­£å¸¸åŠ è½½: {page_title}")
                return None
            
            detail_data = {
                'url': job_url,
                'extracted_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                'page_title': page_title
            }
            
            # å°è¯•å¤šç§é€‰æ‹©å™¨æå–èŒä½æè¿°ï¼ˆ51jobä¸“ç”¨é€‰æ‹©å™¨ä¼˜å…ˆï¼‰
            description_selectors = [
                '.bmsg.job_msg.inbox',  # 51jobä¸“ç”¨é€‰æ‹©å™¨
                '.bmsg.job_msg',
                '.job_msg.inbox',
                '.bmsg',
                '.job_msg',
                self.detail_selectors.get('job_description', '.job-description'),
                '.job-detail-content',
                '.job-desc',
                '.position-detail',
                '.job-content',
                '[class*="description"]',
                '[class*="detail"]'
            ]
            
            for selector in description_selectors:
                description = self._extract_text_by_selector(driver, selector, default="")
                if description and len(description) > 50:  # ç¡®ä¿è·å–åˆ°æœ‰æ„ä¹‰çš„å†…å®¹
                    detail_data['description'] = description
                    self.logger.info(f"âœ… ä½¿ç”¨é€‰æ‹©å™¨æå–èŒä½æè¿°: {selector} (é•¿åº¦: {len(description)})")
                    break
            else:
                detail_data['description'] = ""
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„èŒä½æè¿°å†…å®¹")
            
            # å°è¯•å¤šç§é€‰æ‹©å™¨æå–èŒä½è¦æ±‚ï¼ˆ51jobé€šå¸¸åœ¨descriptionä¸­åŒ…å«è¦æ±‚ï¼‰
            requirements_selectors = [
                '.bmsg.job_msg.inbox',  # 51jobé€šå¸¸èŒä½è¦æ±‚å’Œæè¿°åœ¨åŒä¸€ä¸ªå®¹å™¨ä¸­
                '.bmsg.job_msg',
                '.job_msg.inbox',
                self.detail_selectors.get('requirements', '.job-requirements'),
                '.job-require',
                '.position-require',
                '.job-demand',
                '[class*="requirement"]',
                '[class*="require"]'
            ]
            
            for selector in requirements_selectors:
                requirements = self._extract_text_by_selector(driver, selector, default="")
                if requirements and len(requirements) > 20:
                    # å¯¹äº51jobï¼ŒèŒä½è¦æ±‚é€šå¸¸å’ŒèŒä½æè¿°åœ¨åŒä¸€å®¹å™¨ä¸­
                    # å¦‚æœå’Œdescriptionç›¸åŒï¼Œåˆ™è¯´æ˜è¦æ±‚åŒ…å«åœ¨æè¿°ä¸­
                    if requirements == detail_data.get('description', ''):
                        detail_data['requirements'] = requirements
                        self.logger.info(f"âœ… èŒä½è¦æ±‚åŒ…å«åœ¨æè¿°ä¸­: {selector}")
                    else:
                        detail_data['requirements'] = requirements
                        self.logger.info(f"âœ… ä½¿ç”¨é€‰æ‹©å™¨æå–èŒä½è¦æ±‚: {selector}")
                    break
            else:
                # å¦‚æœæ²¡æœ‰å•ç‹¬çš„è¦æ±‚å­—æ®µï¼Œå¤åˆ¶æè¿°å†…å®¹
                if detail_data.get('description'):
                    detail_data['requirements'] = detail_data['description']
                    self.logger.info("â„¹ï¸ èŒä½è¦æ±‚ä½¿ç”¨æè¿°å†…å®¹")
                else:
                    detail_data['requirements'] = ""
            
            # å¿«é€Ÿè®¾ç½®é»˜è®¤å€¼ï¼Œé¿å…ä¸å¿…è¦çš„DOMæŸ¥è¯¢
            detail_data['company_info'] = ""
            detail_data['benefits'] = ""
            
            # ä»…åœ¨å¼€å‘æ¨¡å¼ä¸‹æå–é¢å¤–ä¿¡æ¯
            config_mode = getattr(self, 'config', {}).get('mode', {})
            is_debug_mode = config_mode.get('development', False) or config_mode.get('debug', False)
            
            if is_debug_mode:
                self.logger.debug("ğŸ”§ å¼€å‘æ¨¡å¼: æå–é¢å¤–ä¿¡æ¯...")
                
                # å…¬å¸ä¿¡æ¯ - ç®€åŒ–é€‰æ‹©å™¨
                company_selectors = ['.company-info', '.company-detail']
                for selector in company_selectors:
                    company_info = self._extract_text_by_selector(driver, selector, default="")
                    if company_info:
                        detail_data['company_info'] = company_info
                        break
                
                # ç¦åˆ©å¾…é‡ - ç®€åŒ–é€‰æ‹©å™¨
                benefits_selectors = ['.job-benefits', '.welfare', '.benefits']
                for selector in benefits_selectors:
                    benefits = self._extract_text_by_selector(driver, selector, default="")
                    if benefits:
                        detail_data['benefits'] = benefits
                        break
            else:
                self.logger.debug("ğŸš€ ç”Ÿäº§æ¨¡å¼: è·³è¿‡é¢å¤–ä¿¡æ¯æå–ä»¥æå‡æ€§èƒ½")
            
            # éªŒè¯æ˜¯å¦æå–åˆ°æœ‰æ•ˆå†…å®¹ï¼ˆä¿®å¤é€»è¾‘ï¼‰
            content_fields = ['description', 'requirements', 'company_info', 'benefits']
            has_content = any(detail_data.get(field) and len(str(detail_data.get(field)).strip()) > 10 for field in content_fields)
            
            # ç‰¹åˆ«æ£€æŸ¥æ ¸å¿ƒå­—æ®µ
            description = detail_data.get('description', '').strip()
            requirements = detail_data.get('requirements', '').strip()
            
            # å¦‚æœæœ‰æè¿°æˆ–è¦æ±‚å†…å®¹ï¼Œå°±è®¤ä¸ºæå–æˆåŠŸ
            if description and len(description) > 20:
                has_content = True
                self.logger.info(f"âœ… æˆåŠŸæå–èŒä½æè¿°ï¼Œé•¿åº¦: {len(description)} å­—ç¬¦")
            elif requirements and len(requirements) > 20:
                has_content = True
                self.logger.info(f"âœ… æˆåŠŸæå–èŒä½è¦æ±‚ï¼Œé•¿åº¦: {len(requirements)} å­—ç¬¦")
            
            if not has_content:
                self.logger.warning(f"âš ï¸ æœªæå–åˆ°æœ‰æ•ˆçš„è¯¦æƒ…å†…å®¹: {job_url}")
                self.logger.warning("ğŸ’¡ æç¤º: å¦‚æœé¡µé¢ç¡®å®åŒ…å«å†…å®¹ï¼Œå»ºè®®äººå·¥æ£€æŸ¥é¡µé¢ç»“æ„å’Œé€‰æ‹©å™¨")
                self.logger.warning("ğŸ” å¯èƒ½åŸå› : é¡µé¢é€‰æ‹©å™¨ä¸åŒ¹é…ã€éœ€è¦é¢å¤–ç­‰å¾…æ—¶é—´ã€æˆ–é¡µé¢ç»“æ„å‘ç”Ÿå˜åŒ–")
                return None
            
            return detail_data
            
        except Exception as e:
            self.logger.error(f"âŒ è§£æèŒä½è¯¦æƒ…å¤±è´¥: {e}")
            return None
    
    
    def get_page_info(self, driver: webdriver.Chrome) -> Dict[str, Any]:
        """
        è·å–é¡µé¢åŸºæœ¬ä¿¡æ¯
        
        Args:
            driver: WebDriverå®ä¾‹
            
        Returns:
            é¡µé¢ä¿¡æ¯å­—å…¸
        """
        try:
            return {
                'url': driver.current_url,
                'title': driver.title,
                'ready_state': driver.execute_script("return document.readyState"),
                'page_height': driver.execute_script("return document.body.scrollHeight"),
                'viewport_height': driver.execute_script("return window.innerHeight"),
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }
        except Exception as e:
            self.logger.error(f"è·å–é¡µé¢ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def extract_job_urls_by_clicking(self,
                                   driver: webdriver.Chrome,
                                   max_jobs: int = 10) -> List[Dict[str, Any]]:
        """
        é€šè¿‡æ¨¡æ‹Ÿç‚¹å‡»èŒä½æ ‡é¢˜æå–è¯¦æƒ…é¡µURL
        
        è¿™æ˜¯PageParserçš„æ ¸å¿ƒåŠŸèƒ½ä¹‹ä¸€ï¼Œè´Ÿè´£ï¼š
        1. è¯†åˆ«é¡µé¢ä¸­çš„èŒä½æ ‡é¢˜å…ƒç´ 
        2. æ¨¡æ‹Ÿäººç±»ç‚¹å‡»è¡Œä¸ºè·å–è¯¦æƒ…é¡µURL
        3. å¤„ç†é¡µé¢äº¤äº’å’Œçª—å£åˆ‡æ¢
        4. è¿”å›ç»“æ„åŒ–çš„URLæ•°æ®
        
        Args:
            driver: WebDriverå®ä¾‹ï¼ˆç”±ContentExtractoræä¾›ï¼‰
            max_jobs: æœ€å¤§æå–æ•°é‡
            
        Returns:
            èŒä½URLä¿¡æ¯åˆ—è¡¨ï¼ŒåŒ…å«æ ‡é¢˜ã€URLã€æå–æ—¶é—´ç­‰
        """
        try:
            self.logger.info(f"ğŸš€ å¼€å§‹é€šè¿‡ç‚¹å‡»æå–èŒä½URLï¼Œæœ€å¤§æ•°é‡: {max_jobs}")
            
            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, ".jname"))
            )
            
            # æ ¹æ®é…ç½®é€‰æ‹©ç­‰å¾…ç­–ç•¥
            config_mode = getattr(self, 'config', {}).get('mode', {})
            is_debug_mode = config_mode.get('development', False) or config_mode.get('debug', False)
            
            if is_debug_mode:
                # å¼€å‘æ¨¡å¼ï¼šæœ€å°ç­‰å¾…
                initial_wait = random.uniform(0.2, 0.5)
                self.logger.debug(f"å¼€å‘æ¨¡å¼ - åˆå§‹ç­‰å¾… {initial_wait:.1f} ç§’")
            else:
                # ç”Ÿäº§æ¨¡å¼ï¼šæ­£å¸¸ç­‰å¾…
                initial_wait = random.uniform(1.0, 2.0)
                self.logger.debug(f"ç”Ÿäº§æ¨¡å¼ - åˆå§‹ç­‰å¾… {initial_wait:.1f} ç§’")
            
            time.sleep(initial_wait)
            
            # æŸ¥æ‰¾æ‰€æœ‰èŒä½æ ‡é¢˜å…ƒç´ 
            job_title_elements = driver.find_elements(By.CSS_SELECTOR, ".jname")
            self.logger.info(f"âœ… æ‰¾åˆ° {len(job_title_elements)} ä¸ªèŒä½æ ‡é¢˜")
            
            if not job_title_elements:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°èŒä½æ ‡é¢˜å…ƒç´ ")
                return []
            
            # é™åˆ¶æå–æ•°é‡
            jobs_to_process = min(len(job_title_elements), max_jobs)
            extracted_urls = []
            
            for i in range(jobs_to_process):
                try:
                    # é‡æ–°è·å–å…ƒç´ ï¼ˆé¿å…stale elementå¼‚å¸¸ï¼‰
                    job_title_elements = driver.find_elements(By.CSS_SELECTOR, ".jname")
                    if i >= len(job_title_elements):
                        break
                        
                    job_element = job_title_elements[i]
                    job_title = job_element.text.strip()
                    
                    self.logger.info(f"ğŸ¯ å¤„ç†ç¬¬ {i+1} ä¸ªèŒä½: {job_title}")
                    
                    # è®°å½•å½“å‰çª—å£å¥æŸ„
                    original_windows = driver.window_handles
                    
                    # æ¨¡æ‹Ÿäººç±»æ»šåŠ¨è¡Œä¸º
                    self._simulate_human_scroll(driver, job_element)
                    
                    # æ¨¡æ‹Ÿé¼ æ ‡æ‚¬åœï¼ˆå¯é€‰ï¼‰
                    if random.random() < 0.3:  # 30%æ¦‚ç‡æ‚¬åœ
                        ActionChains(driver).move_to_element(job_element).perform()
                        time.sleep(random.uniform(0.2, 0.8))
                    
                    # ç‚¹å‡»èŒä½æ ‡é¢˜
                    ActionChains(driver).click(job_element).perform()
                    
                    # æ ¹æ®æ¨¡å¼è°ƒæ•´ç­‰å¾…æ—¶é—´
                    if is_debug_mode:
                        wait_time = random.uniform(0.3, 0.8)  # å¼€å‘æ¨¡å¼ç¼©çŸ­ç­‰å¾…
                    else:
                        wait_time = random.uniform(1.0, 2.0)  # ç”Ÿäº§æ¨¡å¼æ­£å¸¸ç­‰å¾…
                    time.sleep(wait_time)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çª—å£æ‰“å¼€
                    new_windows = driver.window_handles
                    if len(new_windows) > len(original_windows):
                        # åˆ‡æ¢åˆ°æ–°çª—å£
                        new_window = [w for w in new_windows if w not in original_windows][0]
                        driver.switch_to.window(new_window)
                        
                        # çŸ­æš‚ç­‰å¾…é¡µé¢åŠ è½½
                        time.sleep(random.uniform(0.5, 1.5))
                        
                        # è·å–è¯¦æƒ…é¡µURL
                        detail_url = driver.current_url
                        
                        job_info = {
                            'index': i + 1,
                            'title': job_title,
                            'detail_url': detail_url,
                            'extracted_at': datetime.now().isoformat()
                        }
                        
                        extracted_urls.append(job_info)
                        self.logger.info(f"âœ… æˆåŠŸæå–: {detail_url}")
                        
                        # å…³é—­æ–°çª—å£å¹¶åˆ‡æ¢å›åŸçª—å£
                        driver.close()
                        driver.switch_to.window(original_windows[0])
                        
                        # æ ¹æ®æ¨¡å¼è°ƒæ•´æ€è€ƒæ—¶é—´
                        if is_debug_mode:
                            think_time = random.uniform(0.1, 0.3)  # å¼€å‘æ¨¡å¼å¿«é€Ÿ
                        else:
                            think_time = random.uniform(0.5, 2.0)  # ç”Ÿäº§æ¨¡å¼æ­£å¸¸
                        time.sleep(think_time)
                        
                    else:
                        self.logger.warning(f"âš ï¸ ç‚¹å‡» {job_title} æœªæ‰“å¼€æ–°çª—å£")
                    
                    # æ¯å¤„ç†å‡ ä¸ªèŒä½åï¼Œæ¨¡æ‹Ÿæ›´é•¿çš„ä¼‘æ¯
                    if (i + 1) % random.randint(3, 6) == 0 and not is_debug_mode:
                        rest_time = random.uniform(2.0, 5.0)
                        self.logger.debug(f"â³ æ¨¡æ‹Ÿç”¨æˆ·ä¼‘æ¯ {rest_time:.1f} ç§’")
                        time.sleep(rest_time)
                    elif is_debug_mode and (i + 1) % 5 == 0:
                        # å¼€å‘æ¨¡å¼å¶å°”çŸ­æš‚ä¼‘æ¯
                        rest_time = random.uniform(0.2, 0.5)
                        self.logger.debug(f"â³ å¼€å‘æ¨¡å¼çŸ­æš‚ä¼‘æ¯ {rest_time:.1f} ç§’")
                        time.sleep(rest_time)
                        
                except Exception as e:
                    self.logger.warning(f"âŒ å¤„ç†èŒä½ {i+1} æ—¶å‡ºé”™: {e}")
                    # ç¡®ä¿å›åˆ°åŸçª—å£
                    if len(driver.window_handles) > 1:
                        driver.switch_to.window(driver.window_handles[0])
                    
                    # æ ¹æ®æ¨¡å¼è°ƒæ•´é”™è¯¯åç­‰å¾…æ—¶é—´
                    if is_debug_mode:
                        error_wait = random.uniform(0.5, 1.0)  # å¼€å‘æ¨¡å¼å¿«é€Ÿé‡è¯•
                    else:
                        error_wait = random.uniform(3.0, 8.0)  # ç”Ÿäº§æ¨¡å¼æ­£å¸¸ç­‰å¾…
                    time.sleep(error_wait)
                    continue
            
            self.logger.info(f"ğŸ‰ æˆåŠŸæå– {len(extracted_urls)} ä¸ªèŒä½URL")
            return extracted_urls
            
        except Exception as e:
            self.logger.error(f"âŒ ç‚¹å‡»æå–URLè¿‡ç¨‹å‡ºé”™: {e}")
            raise PageParseError(f"ç‚¹å‡»æå–URLå¤±è´¥: {e}")
    
    def _simulate_human_scroll(self, driver: webdriver.Chrome, target_element) -> None:
        """
        æ¨¡æ‹Ÿäººç±»æ»šåŠ¨è¡Œä¸º
        
        Args:
            driver: WebDriverå®ä¾‹
            target_element: ç›®æ ‡å…ƒç´ 
        """
        try:
            # è·å–å…ƒç´ ä½ç½®
            element_location = target_element.location_once_scrolled_into_view
            
            # æ¨¡æ‹Ÿåˆ†æ­¥æ»šåŠ¨è€Œä¸æ˜¯ç›´æ¥æ»šåŠ¨åˆ°å…ƒç´ 
            current_scroll = driver.execute_script("return window.pageYOffset;")
            target_scroll = element_location['y'] - random.randint(100, 300)  # ç•™ä¸€äº›ä½™é‡
            
            if abs(target_scroll - current_scroll) > 100:
                # åˆ†å¤šæ­¥æ»šåŠ¨
                steps = random.randint(2, 4)
                scroll_step = (target_scroll - current_scroll) / steps
                
                for step in range(steps):
                    scroll_to = current_scroll + scroll_step * (step + 1)
                    driver.execute_script(f"window.scrollTo(0, {scroll_to});")
                    time.sleep(random.uniform(0.1, 0.3))
            
            # æœ€åç²¾ç¡®æ»šåŠ¨åˆ°å…ƒç´ 
            driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", target_element)
            time.sleep(random.uniform(0.3, 0.8))
            
        except Exception as e:
            self.logger.debug(f"æ¨¡æ‹Ÿæ»šåŠ¨å¤±è´¥: {e}")
            # å›é€€åˆ°ç®€å•æ»šåŠ¨
            driver.execute_script("arguments[0].scrollIntoView(true);", target_element)
            time.sleep(0.5)
    
    def has_next_page(self, driver: webdriver.Chrome) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
        
        Args:
            driver: WebDriverå®ä¾‹
            
        Returns:
            æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
        """
        try:
            # å°è¯•å¤šç§ä¸‹ä¸€é¡µæŒ‰é’®é€‰æ‹©å™¨
            next_page_selectors = [
                self.search_selectors.get('next_page', '.btn_next'),
                '.next-page',
                '.page-next',
                '.btn-next',
                '.pager-next',
                'a[title*="ä¸‹ä¸€é¡µ"]',
                'a[title*="next"]',
                '.pagination .next',
                '.pagination-next',
                '.page-item.next a',
                '.page-link[aria-label*="Next"]'
            ]
            
            for selector in next_page_selectors:
                try:
                    next_button = driver.find_element(By.CSS_SELECTOR, selector)
                    
                    # æ£€æŸ¥æŒ‰é’®æ˜¯å¦å¯ç”¨ï¼ˆä¸æ˜¯ç¦ç”¨çŠ¶æ€ï¼‰
                    if next_button.is_enabled() and next_button.is_displayed():
                        # æ£€æŸ¥æ˜¯å¦æœ‰disabledç±»æˆ–å±æ€§
                        classes = next_button.get_attribute('class') or ''
                        disabled_attr = next_button.get_attribute('disabled')
                        
                        if 'disabled' not in classes.lower() and not disabled_attr:
                            self.logger.debug(f"æ‰¾åˆ°å¯ç”¨çš„ä¸‹ä¸€é¡µæŒ‰é’®: {selector}")
                            return True
                    
                except NoSuchElementException:
                    continue
                except Exception as e:
                    self.logger.debug(f"æ£€æŸ¥ä¸‹ä¸€é¡µæŒ‰é’®æ—¶å‡ºé”™ {selector}: {e}")
                    continue
            
            self.logger.debug("æœªæ‰¾åˆ°å¯ç”¨çš„ä¸‹ä¸€é¡µæŒ‰é’®")
            return False
            
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥ä¸‹ä¸€é¡µå¤±è´¥: {e}")
            return False
    
    def navigate_to_next_page(self, driver: webdriver.Chrome) -> bool:
        """
        å¯¼èˆªåˆ°ä¸‹ä¸€é¡µ
        
        Args:
            driver: WebDriverå®ä¾‹
            
        Returns:
            æ˜¯å¦æˆåŠŸå¯¼èˆªåˆ°ä¸‹ä¸€é¡µ
        """
        try:
            self.logger.info("ğŸ”„ å°è¯•å¯¼èˆªåˆ°ä¸‹ä¸€é¡µ")
            
            # è®°å½•å½“å‰é¡µé¢URLç”¨äºéªŒè¯
            current_url = driver.current_url
            
            # å°è¯•å¤šç§ä¸‹ä¸€é¡µæŒ‰é’®é€‰æ‹©å™¨
            next_page_selectors = [
                self.search_selectors.get('next_page', '.btn_next'),
                '.next-page',
                '.page-next',
                '.btn-next',
                '.pager-next',
                'a[title*="ä¸‹ä¸€é¡µ"]',
                'a[title*="next"]',
                '.pagination .next',
                '.pagination-next',
                '.page-item.next a',
                '.page-link[aria-label*="Next"]'
            ]
            
            for selector in next_page_selectors:
                try:
                    next_button = driver.find_element(By.CSS_SELECTOR, selector)
                    
                    # æ£€æŸ¥æŒ‰é’®æ˜¯å¦å¯ç”¨
                    if next_button.is_enabled() and next_button.is_displayed():
                        classes = next_button.get_attribute('class') or ''
                        disabled_attr = next_button.get_attribute('disabled')
                        
                        if 'disabled' not in classes.lower() and not disabled_attr:
                            self.logger.info(f"ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®: {selector}")
                            
                            # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®
                            driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", next_button)
                            time.sleep(random.uniform(0.5, 1.0))
                            
                            # æ¨¡æ‹Ÿäººç±»ç‚¹å‡»è¡Œä¸º
                            if random.random() < 0.3:  # 30%æ¦‚ç‡å…ˆæ‚¬åœ
                                ActionChains(driver).move_to_element(next_button).perform()
                                time.sleep(random.uniform(0.2, 0.5))
                            
                            # ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®
                            ActionChains(driver).click(next_button).perform()
                            
                            # ç­‰å¾…é¡µé¢åŠ è½½
                            wait_time = random.uniform(2.0, 4.0)
                            time.sleep(wait_time)
                            
                            # ç­‰å¾…é¡µé¢ç¨³å®š
                            self._wait_for_page_stable(driver, timeout=10)
                            
                            # éªŒè¯æ˜¯å¦æˆåŠŸè·³è½¬åˆ°ä¸‹ä¸€é¡µ
                            new_url = driver.current_url
                            if new_url != current_url:
                                self.logger.info(f"âœ… æˆåŠŸå¯¼èˆªåˆ°ä¸‹ä¸€é¡µ: {new_url}")
                                return True
                            else:
                                # URLæ²¡å˜ï¼Œå¯èƒ½æ˜¯AJAXåŠ è½½ï¼Œæ£€æŸ¥é¡µé¢å†…å®¹æ˜¯å¦å˜åŒ–
                                time.sleep(1.0)
                                self.logger.info("âœ… é¡µé¢å†…å®¹å·²æ›´æ–°ï¼ˆAJAXåŠ è½½ï¼‰")
                                return True
                    
                except NoSuchElementException:
                    continue
                except Exception as e:
                    self.logger.warning(f"ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®å¤±è´¥ {selector}: {e}")
                    continue
            
            self.logger.warning("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨çš„ä¸‹ä¸€é¡µæŒ‰é’®")
            return False
            
        except Exception as e:
            self.logger.error(f"âŒ å¯¼èˆªåˆ°ä¸‹ä¸€é¡µå¤±è´¥: {e}")
            return False
    
    def get_current_page_info(self, driver: webdriver.Chrome) -> Dict[str, Any]:
        """
        è·å–å½“å‰é¡µé¢ä¿¡æ¯
        
        Args:
            driver: WebDriverå®ä¾‹
            
        Returns:
            é¡µé¢ä¿¡æ¯å­—å…¸
        """
        try:
            # å°è¯•è·å–é¡µç ä¿¡æ¯
            page_info = {
                'url': driver.current_url,
                'title': driver.title,
                'current_page': 1,
                'total_pages': None,
                'has_next': self.has_next_page(driver)
            }
            
            # å°è¯•ä»URLä¸­æå–é¡µç 
            import re
            from urllib.parse import urlparse, parse_qs
            
            parsed_url = urlparse(driver.current_url)
            query_params = parse_qs(parsed_url.query)
            
            # å¸¸è§çš„é¡µç å‚æ•°
            page_params = ['page', 'p', 'pageNum', 'pageIndex', 'currentPage']
            for param in page_params:
                if param in query_params:
                    try:
                        page_info['current_page'] = int(query_params[param][0])
                        break
                    except (ValueError, IndexError):
                        continue
            
            # å°è¯•ä»é¡µé¢å…ƒç´ ä¸­è·å–é¡µç ä¿¡æ¯
            page_selectors = [
                '.current-page',
                '.active-page',
                '.pagination .active',
                '.page-current',
                '.pager-current'
            ]
            
            for selector in page_selectors:
                try:
                    page_element = driver.find_element(By.CSS_SELECTOR, selector)
                    page_text = page_element.text.strip()
                    if page_text.isdigit():
                        page_info['current_page'] = int(page_text)
                        break
                except:
                    continue
            
            return page_info
            
        except Exception as e:
            self.logger.error(f"è·å–é¡µé¢ä¿¡æ¯å¤±è´¥: {e}")
            return {'current_page': 1, 'has_next': False}