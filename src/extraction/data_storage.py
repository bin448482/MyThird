"""
æ•°æ®å­˜å‚¨å™¨

è´Ÿè´£ä¿å­˜ã€ç®¡ç†å’ŒæŸ¥è¯¢æå–çš„èŒä½æ•°æ®
åŸºäºCLAUDE.mdä¸­å®šä¹‰çš„æ•°æ®åº“è¡¨ç»“æ„
"""

import json
import csv
import sqlite3
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime
import hashlib

from ..core.exceptions import DataStorageError


class DataStorage:
    """æ•°æ®å­˜å‚¨å™¨"""
    
    def __init__(self, config: dict):
        """
        åˆå§‹åŒ–æ•°æ®å­˜å‚¨å™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.database_config = config.get('database', {})
        self.search_config = config.get('search', {})
        self.logger = logging.getLogger(__name__)
        
        # æ•°æ®ç›®å½•
        self.data_dir = Path("data")
        self.search_results_dir = self.data_dir / "search_results"
        self.job_details_dir = self.data_dir / "job_details"
        
        # åˆ›å»ºç›®å½•
        self._ensure_directories()
        
        # æ•°æ®åº“è·¯å¾„
        self.db_path = self.database_config.get('path', './data/jobs.db')
    
    def _ensure_directories(self) -> None:
        """ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨"""
        try:
            self.data_dir.mkdir(exist_ok=True)
            self.search_results_dir.mkdir(exist_ok=True)
            self.job_details_dir.mkdir(exist_ok=True)
            self.logger.debug("æ•°æ®ç›®å½•å·²åˆ›å»º")
        except Exception as e:
            self.logger.error(f"åˆ›å»ºæ•°æ®ç›®å½•å¤±è´¥: {e}")
    
    def save_search_results(self, 
                          results: List[Dict[str, Any]], 
                          keyword: str,
                          format: str = 'json') -> Optional[str]:
        """
        ä¿å­˜æœç´¢ç»“æœ
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            keyword: æœç´¢å…³é”®è¯
            format: ä¿å­˜æ ¼å¼ ('json', 'csv', 'both')
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not results:
            self.logger.warning("æœç´¢ç»“æœä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜")
            return None
        
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            safe_keyword = self._sanitize_filename(keyword)
            base_filename = f"search_{safe_keyword}_{timestamp}"
            
            saved_files = []
            
            # ä¿å­˜ä¸ºJSONæ ¼å¼
            if format in ['json', 'both']:
                json_file = self.search_results_dir / f"{base_filename}.json"
                if self._save_as_json(results, json_file, keyword):
                    saved_files.append(str(json_file))
            
            # ä¿å­˜ä¸ºCSVæ ¼å¼
            if format in ['csv', 'both']:
                csv_file = self.search_results_dir / f"{base_filename}.csv"
                if self._save_as_csv(results, csv_file):
                    saved_files.append(str(csv_file))
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            if self.database_config.get('enabled', True):
                self._save_to_database(results, keyword)
            
            if saved_files:
                self.logger.info(f"ğŸ’¾ æœç´¢ç»“æœå·²ä¿å­˜: {', '.join(saved_files)}")
                return saved_files[0]  # è¿”å›ç¬¬ä¸€ä¸ªæ–‡ä»¶è·¯å¾„
            else:
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜æœç´¢ç»“æœå¤±è´¥: {e}")
            raise DataStorageError(f"ä¿å­˜æœç´¢ç»“æœå¤±è´¥: {e}")
    
    def _save_as_json(self, results: List[Dict], filepath: Path, keyword: str) -> bool:
        """
        ä¿å­˜ä¸ºJSONæ ¼å¼
        
        Args:
            results: ç»“æœæ•°æ®
            filepath: æ–‡ä»¶è·¯å¾„
            keyword: æœç´¢å…³é”®è¯
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            # æ·»åŠ å…ƒæ•°æ®
            data = {
                'metadata': {
                    'keyword': keyword,
                    'total_count': len(results),
                    'extracted_at': datetime.now().isoformat(),
                    'source': 'qiancheng_automation'
                },
                'results': results
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            self.logger.debug(f"JSONæ–‡ä»¶å·²ä¿å­˜: {filepath}")
            return True
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def _save_as_csv(self, results: List[Dict], filepath: Path) -> bool:
        """
        ä¿å­˜ä¸ºCSVæ ¼å¼
        
        Args:
            results: ç»“æœæ•°æ®
            filepath: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            if not results:
                return False
            
            # è·å–æ‰€æœ‰å­—æ®µå
            fieldnames = set()
            for result in results:
                fieldnames.update(result.keys())
            
            fieldnames = sorted(list(fieldnames))
            
            with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(results)
            
            self.logger.debug(f"CSVæ–‡ä»¶å·²ä¿å­˜: {filepath}")
            return True
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def _save_to_database(self, results: List[Dict], keyword: str) -> bool:
        """
        ä¿å­˜åˆ°SQLiteæ•°æ®åº“ï¼ˆä½¿ç”¨CLAUDE.mdä¸­å®šä¹‰çš„è¡¨ç»“æ„ï¼‰
        
        Args:
            results: ç»“æœæ•°æ®
            keyword: æœç´¢å…³é”®è¯
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            # ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨
            db_path = Path(self.db_path)
            db_path.parent.mkdir(parents=True, exist_ok=True)
            
            with sqlite3.connect(self.db_path) as conn:
                # åˆ›å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                self._create_tables(conn)
                
                # æ’å…¥æ•°æ®
                cursor = conn.cursor()
                
                for result in results:
                    # ç”Ÿæˆjob_idï¼ˆåŸºäºURLçš„å“ˆå¸Œå€¼ï¼‰
                    job_url = result.get('url', '')
                    job_id = self._generate_job_id(job_url, result.get('title', ''), result.get('company', ''))
                    
                    # æ’å…¥èŒä½æ•°æ®ï¼ˆä½¿ç”¨CLAUDE.mdä¸­å®šä¹‰çš„è¡¨ç»“æ„ï¼‰
                    cursor.execute("""
                        INSERT OR REPLACE INTO jobs (
                            job_id, title, company, url, application_status, 
                            match_score, website, created_at, submitted_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        job_id,
                        result.get('title', ''),
                        result.get('company', ''),
                        job_url,
                        'pending',  # é»˜è®¤çŠ¶æ€
                        None,  # åŒ¹é…åº¦è¯„åˆ†å¾…åç»­è®¡ç®—
                        'qiancheng',  # æ¥æºç½‘ç«™
                        datetime.now().isoformat(),
                        None  # æŠ•é€’æ—¶é—´
                    ))
                
                conn.commit()
                self.logger.debug(f"æ•°æ®åº“å·²ä¿å­˜ {len(results)} æ¡è®°å½•")
                return True
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    def _create_tables(self, conn: sqlite3.Connection) -> None:
        """
        åˆ›å»ºæ•°æ®åº“è¡¨ï¼ˆåŸºäºCLAUDE.mdä¸­çš„å®šä¹‰ï¼‰
        
        Args:
            conn: æ•°æ®åº“è¿æ¥
        """
        cursor = conn.cursor()
        
        # åˆ›å»ºèŒä½è¡¨ï¼ˆæŒ‰ç…§CLAUDE.mdä¸­çš„å®šä¹‰ï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS jobs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                job_id VARCHAR(100) UNIQUE NOT NULL,
                title VARCHAR(200) NOT NULL,
                company VARCHAR(200) NOT NULL,
                url VARCHAR(500) NOT NULL,
                application_status VARCHAR(50) DEFAULT 'pending',
                match_score FLOAT,
                website VARCHAR(50) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                submitted_at TIMESTAMP
            )
        """)
        
        # åˆ›å»ºæ‰©å±•ä¿¡æ¯è¡¨ï¼ˆå­˜å‚¨é¢å¤–çš„èŒä½ä¿¡æ¯ï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS job_details (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                job_id VARCHAR(100) NOT NULL,
                salary TEXT,
                location TEXT,
                experience TEXT,
                education TEXT,
                description TEXT,
                requirements TEXT,
                benefits TEXT,
                publish_time TEXT,
                company_scale TEXT,
                industry TEXT,
                keyword TEXT,
                extracted_at TEXT,
                FOREIGN KEY (job_id) REFERENCES jobs (job_id)
            )
        """)
        
        # åˆ›å»ºæœç´¢å†å²è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS search_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                keyword TEXT NOT NULL,
                results_count INTEGER,
                search_time DATETIME DEFAULT CURRENT_TIMESTAMP,
                file_path TEXT
            )
        """)
        
        # åˆ›å»ºç´¢å¼•
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_jobs_job_id ON jobs(job_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_jobs_company ON jobs(company)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_jobs_website ON jobs(website)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_job_details_job_id ON job_details(job_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_job_details_keyword ON job_details(keyword)")
        
        conn.commit()
    
    def _generate_job_id(self, url: str, title: str, company: str) -> str:
        """
        ç”ŸæˆèŒä½å”¯ä¸€æ ‡è¯†
        
        Args:
            url: èŒä½URL
            title: èŒä½æ ‡é¢˜
            company: å…¬å¸åç§°
            
        Returns:
            èŒä½ID
        """
        # ä¼˜å…ˆä»URLä¸­æå–ID
        if url:
            import re
            match = re.search(r'/(\d+)\.html?', url)
            if match:
                return f"qc_{match.group(1)}"
            
            match = re.search(r'jobid[=:](\d+)', url, re.IGNORECASE)
            if match:
                return f"qc_{match.group(1)}"
        
        # å¦‚æœæ— æ³•ä»URLæå–ï¼Œåˆ™åŸºäºæ ‡é¢˜å’Œå…¬å¸ç”Ÿæˆå“ˆå¸Œ
        content = f"{title}_{company}_{url}"
        hash_obj = hashlib.md5(content.encode('utf-8'))
        return f"qc_{hash_obj.hexdigest()[:12]}"
    
    def save_job_details(self, results: List[Dict[str, Any]], keyword: str) -> bool:
        """
        ä¿å­˜èŒä½è¯¦ç»†ä¿¡æ¯åˆ°æ‰©å±•è¡¨
        
        Args:
            results: èŒä½è¯¦ç»†ä¿¡æ¯åˆ—è¡¨
            keyword: æœç´¢å…³é”®è¯
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                for result in results:
                    job_url = result.get('url', '')
                    job_id = self._generate_job_id(job_url, result.get('title', ''), result.get('company', ''))
                    
                    # æ’å…¥æˆ–æ›´æ–°èŒä½è¯¦ç»†ä¿¡æ¯
                    cursor.execute("""
                        INSERT OR REPLACE INTO job_details (
                            job_id, salary, location, experience, education,
                            description, requirements, benefits, publish_time,
                            company_scale, industry, keyword, extracted_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        job_id,
                        result.get('salary', ''),
                        result.get('location', ''),
                        result.get('experience', ''),
                        result.get('education', ''),
                        result.get('description', ''),
                        result.get('requirements', ''),
                        result.get('benefits', ''),
                        result.get('publish_time', ''),
                        result.get('company_scale', ''),
                        result.get('industry', ''),
                        keyword,
                        result.get('extracted_at', datetime.now().isoformat())
                    ))
                
                conn.commit()
                self.logger.debug(f"èŒä½è¯¦ç»†ä¿¡æ¯å·²ä¿å­˜ {len(results)} æ¡è®°å½•")
                return True
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜èŒä½è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
            return False
    
    def _sanitize_filename(self, filename: str) -> str:
        """
        æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦
        
        Args:
            filename: åŸå§‹æ–‡ä»¶å
            
        Returns:
            æ¸…ç†åçš„æ–‡ä»¶å
        """
        import re
        # ç§»é™¤æˆ–æ›¿æ¢éæ³•å­—ç¬¦
        sanitized = re.sub(r'[<>:"/\\|?*]', '_', filename)
        # é™åˆ¶é•¿åº¦
        return sanitized[:50] if len(sanitized) > 50 else sanitized
    
    def load_search_results(self, filepath: str) -> Optional[Dict[str, Any]]:
        """
        åŠ è½½æœç´¢ç»“æœ
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æœç´¢ç»“æœæ•°æ®
        """
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.logger.info(f"ğŸ“‚ æœç´¢ç»“æœå·²åŠ è½½: {filepath}")
            return data
            
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½æœç´¢ç»“æœå¤±è´¥: {e}")
            return None
    
    def query_jobs(self, 
                   keyword: Optional[str] = None,
                   company: Optional[str] = None,
                   location: Optional[str] = None,
                   status: Optional[str] = None,
                   limit: int = 100) -> List[Dict[str, Any]]:
        """
        æŸ¥è¯¢èŒä½æ•°æ®
        
        Args:
            keyword: å…³é”®è¯è¿‡æ»¤
            company: å…¬å¸åè¿‡æ»¤
            location: åœ°ç‚¹è¿‡æ»¤
            status: çŠ¶æ€è¿‡æ»¤
            limit: ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            èŒä½æ•°æ®åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row  # è¿”å›å­—å…¸æ ¼å¼
                cursor = conn.cursor()
                
                # æ„å»ºæŸ¥è¯¢æ¡ä»¶
                conditions = []
                params = []
                
                if keyword:
                    conditions.append("(j.title LIKE ? OR jd.keyword LIKE ?)")
                    params.extend([f"%{keyword}%", f"%{keyword}%"])
                
                if company:
                    conditions.append("j.company LIKE ?")
                    params.append(f"%{company}%")
                
                if location:
                    conditions.append("jd.location LIKE ?")
                    params.append(f"%{location}%")
                
                if status:
                    conditions.append("j.application_status = ?")
                    params.append(status)
                
                # æ„å»ºSQLæŸ¥è¯¢ï¼ˆè”åˆæŸ¥è¯¢ä¸»è¡¨å’Œè¯¦æƒ…è¡¨ï¼‰
                sql = """
                    SELECT j.*, jd.salary, jd.location, jd.experience, jd.education,
                           jd.description, jd.requirements, jd.benefits, jd.publish_time,
                           jd.company_scale, jd.industry, jd.keyword
                    FROM jobs j
                    LEFT JOIN job_details jd ON j.job_id = jd.job_id
                """
                
                if conditions:
                    sql += " WHERE " + " AND ".join(conditions)
                sql += " ORDER BY j.created_at DESC LIMIT ?"
                params.append(limit)
                
                cursor.execute(sql, params)
                rows = cursor.fetchall()
                
                # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                results = [dict(row) for row in rows]
                
                self.logger.info(f"ğŸ“Š æŸ¥è¯¢åˆ° {len(results)} æ¡èŒä½è®°å½•")
                return results
                
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è¯¢èŒä½æ•°æ®å¤±è´¥: {e}")
            return []
    
    def get_search_statistics(self) -> Dict[str, Any]:
        """
        è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # æ€»èŒä½æ•°
                cursor.execute("SELECT COUNT(*) FROM jobs")
                total_jobs = cursor.fetchone()[0]
                
                # æŒ‰ç½‘ç«™ç»Ÿè®¡
                cursor.execute("""
                    SELECT website, COUNT(*) as count 
                    FROM jobs 
                    GROUP BY website 
                    ORDER BY count DESC
                """)
                website_stats = cursor.fetchall()
                
                # æŒ‰çŠ¶æ€ç»Ÿè®¡
                cursor.execute("""
                    SELECT application_status, COUNT(*) as count 
                    FROM jobs 
                    GROUP BY application_status 
                    ORDER BY count DESC
                """)
                status_stats = cursor.fetchall()
                
                # æŒ‰å…¬å¸ç»Ÿè®¡ï¼ˆå‰10ï¼‰
                cursor.execute("""
                    SELECT company, COUNT(*) as count 
                    FROM jobs 
                    WHERE company != '' 
                    GROUP BY company 
                    ORDER BY count DESC 
                    LIMIT 10
                """)
                company_stats = cursor.fetchall()
                
                # æŒ‰å…³é”®è¯ç»Ÿè®¡ï¼ˆå‰10ï¼‰
                cursor.execute("""
                    SELECT keyword, COUNT(*) as count 
                    FROM job_details 
                    WHERE keyword != '' 
                    GROUP BY keyword 
                    ORDER BY count DESC 
                    LIMIT 10
                """)
                keyword_stats = cursor.fetchall()
                
                return {
                    'total_jobs': total_jobs,
                    'website_stats': website_stats,
                    'status_stats': status_stats,
                    'company_stats': company_stats,
                    'keyword_stats': keyword_stats,
                    'generated_at': datetime.now().isoformat()
                }
                
        except Exception as e:
            self.logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def update_job_status(self, job_id: str, status: str, submitted_at: Optional[str] = None) -> bool:
        """
        æ›´æ–°èŒä½çŠ¶æ€
        
        Args:
            job_id: èŒä½ID
            status: æ–°çŠ¶æ€
            submitted_at: æŠ•é€’æ—¶é—´
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                if submitted_at:
                    cursor.execute("""
                        UPDATE jobs 
                        SET application_status = ?, submitted_at = ? 
                        WHERE job_id = ?
                    """, (status, submitted_at, job_id))
                else:
                    cursor.execute("""
                        UPDATE jobs 
                        SET application_status = ? 
                        WHERE job_id = ?
                    """, (status, job_id))
                
                conn.commit()
                
                if cursor.rowcount > 0:
                    self.logger.info(f"èŒä½çŠ¶æ€å·²æ›´æ–°: {job_id} -> {status}")
                    return True
                else:
                    self.logger.warning(f"æœªæ‰¾åˆ°èŒä½: {job_id}")
                    return False
                    
        except Exception as e:
            self.logger.error(f"æ›´æ–°èŒä½çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def list_saved_files(self, directory: str = "search_results") -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºä¿å­˜çš„æ–‡ä»¶
        
        Args:
            directory: ç›®å½•å ('search_results' æˆ– 'job_details')
            
        Returns:
            æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
        """
        try:
            if directory == "search_results":
                target_dir = self.search_results_dir
            elif directory == "job_details":
                target_dir = self.job_details_dir
            else:
                target_dir = self.data_dir / directory
            
            if not target_dir.exists():
                return []
            
            files = []
            for file_path in target_dir.glob("*.json"):
                try:
                    stat = file_path.stat()
                    files.append({
                        'filename': file_path.name,
                        'filepath': str(file_path),
                        'size': stat.st_size,
                        'modified_time': datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        'created_time': datetime.fromtimestamp(stat.st_ctime).isoformat()
                    })
                except Exception as e:
                    self.logger.warning(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {file_path}: {e}")
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
            files.sort(key=lambda x: x['modified_time'], reverse=True)
            
            return files
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {e}")
            return []