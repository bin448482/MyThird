"""
æ•°æ®å­˜å‚¨å™¨

è´Ÿè´£ä¿å­˜ã€ç®¡ç†å’ŒæŸ¥è¯¢æå–çš„èŒä½æ•°æ®
åŸºäºCLAUDE.mdä¸­å®šä¹‰çš„æ•°æ®åº“è¡¨ç»“æ„
"""

import json
import csv
import sqlite3
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime
import hashlib

from ..core.exceptions import DataStorageError
from ..utils.fingerprint import generate_job_fingerprint, extract_job_key_info
from ..database.operations import DatabaseManager


class DataStorage:
    """æ•°æ®å­˜å‚¨å™¨"""
    
    def __init__(self, config: dict):
        """
        åˆå§‹åŒ–æ•°æ®å­˜å‚¨å™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.database_config = config.get('database', {})
        self.search_config = config.get('search', {})
        self.logger = logging.getLogger(__name__)
        
        # æ•°æ®ç›®å½•
        self.data_dir = Path("data")
        self.search_results_dir = self.data_dir / "search_results"
        self.job_details_dir = self.data_dir / "job_details"
        
        # åˆ›å»ºç›®å½•
        self._ensure_directories()
        
        # æ•°æ®åº“è·¯å¾„
        self.db_path = self.database_config.get('path', './data/jobs.db')
    
    def _ensure_directories(self) -> None:
        """ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨"""
        try:
            self.data_dir.mkdir(exist_ok=True)
            self.search_results_dir.mkdir(exist_ok=True)
            self.job_details_dir.mkdir(exist_ok=True)
            self.logger.debug("æ•°æ®ç›®å½•å·²åˆ›å»º")
        except Exception as e:
            self.logger.error(f"åˆ›å»ºæ•°æ®ç›®å½•å¤±è´¥: {e}")
    
    def save_search_results(self, 
                          results: List[Dict[str, Any]], 
                          keyword: str,
                          format: str = 'json') -> Optional[str]:
        """
        ä¿å­˜æœç´¢ç»“æœ
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            keyword: æœç´¢å…³é”®è¯
            format: ä¿å­˜æ ¼å¼ ('json', 'csv', 'both')
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not results:
            self.logger.warning("æœç´¢ç»“æœä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜")
            return None
        
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            safe_keyword = self._sanitize_filename(keyword)
            base_filename = f"search_{safe_keyword}_{timestamp}"
            
            saved_files = []
            
            # ä¿å­˜ä¸ºJSONæ ¼å¼
            if format in ['json', 'both']:
                json_file = self.search_results_dir / f"{base_filename}.json"
                if self._save_as_json(results, json_file, keyword):
                    saved_files.append(str(json_file))
            
            # ä¿å­˜ä¸ºCSVæ ¼å¼
            if format in ['csv', 'both']:
                csv_file = self.search_results_dir / f"{base_filename}.csv"
                if self._save_as_csv(results, csv_file):
                    saved_files.append(str(csv_file))
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            if self.database_config.get('enabled', True):
                self._save_to_database(results, keyword)
            
            if saved_files:
                self.logger.info(f"ğŸ’¾ æœç´¢ç»“æœå·²ä¿å­˜: {', '.join(saved_files)}")
                return saved_files[0]  # è¿”å›ç¬¬ä¸€ä¸ªæ–‡ä»¶è·¯å¾„
            else:
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜æœç´¢ç»“æœå¤±è´¥: {e}")
            raise DataStorageError(f"ä¿å­˜æœç´¢ç»“æœå¤±è´¥: {e}")
    
    def _save_as_json(self, results: List[Dict], filepath: Path, keyword: str) -> bool:
        """
        ä¿å­˜ä¸ºJSONæ ¼å¼
        
        Args:
            results: ç»“æœæ•°æ®
            filepath: æ–‡ä»¶è·¯å¾„
            keyword: æœç´¢å…³é”®è¯
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            # æ·»åŠ å…ƒæ•°æ®
            data = {
                'metadata': {
                    'keyword': keyword,
                    'total_count': len(results),
                    'extracted_at': datetime.now().isoformat(),
                    'source': 'qiancheng_automation'
                },
                'results': results
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            self.logger.debug(f"JSONæ–‡ä»¶å·²ä¿å­˜: {filepath}")
            return True
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def _save_as_csv(self, results: List[Dict], filepath: Path) -> bool:
        """
        ä¿å­˜ä¸ºCSVæ ¼å¼
        
        Args:
            results: ç»“æœæ•°æ®
            filepath: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            if not results:
                return False
            
            # è·å–æ‰€æœ‰å­—æ®µå
            fieldnames = set()
            for result in results:
                fieldnames.update(result.keys())
            
            fieldnames = sorted(list(fieldnames))
            
            with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(results)
            
            self.logger.debug(f"CSVæ–‡ä»¶å·²ä¿å­˜: {filepath}")
            return True
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def _save_to_database(self, results: List[Dict], keyword: str) -> bool:
        """
        ä¿å­˜åˆ°SQLiteæ•°æ®åº“ï¼ˆä½¿ç”¨æŒ‡çº¹å»é‡ï¼‰
        
        Args:
            results: ç»“æœæ•°æ®
            keyword: æœç´¢å…³é”®è¯
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            # ä½¿ç”¨DatabaseManagerè¿›è¡Œæ“ä½œ
            db_manager = DatabaseManager(self.db_path)
            db_manager.init_database()
            
            saved_count = 0
            skipped_count = 0
            
            for result in results:
                # ç”Ÿæˆjob_idå’ŒæŒ‡çº¹
                job_url = result.get('url', '')
                job_id = self._generate_job_id(job_url, result.get('title', ''), result.get('company', ''))
                
                # ç”ŸæˆèŒä½æŒ‡çº¹
                job_fingerprint = generate_job_fingerprint(
                    result.get('title', ''),
                    result.get('company', ''),
                    result.get('salary', ''),
                    result.get('location', '')
                )
                
                # æ£€æŸ¥æŒ‡çº¹æ˜¯å¦å·²å­˜åœ¨
                if db_manager.fingerprint_exists(job_fingerprint):
                    skipped_count += 1
                    self.logger.debug(f"è·³è¿‡é‡å¤èŒä½: {result.get('title', '')} - {result.get('company', '')}")
                    continue
                
                # å‡†å¤‡èŒä½æ•°æ®
                job_data = {
                    'job_id': job_id,
                    'title': result.get('title', ''),
                    'company': result.get('company', ''),
                    'url': job_url,
                    'job_fingerprint': job_fingerprint,
                    'application_status': 'pending',
                    'match_score': None,
                    'website': result.get('source', 'qiancheng'),
                    'created_at': datetime.now().isoformat(),
                    'submitted_at': None
                }
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                if db_manager.save_job(job_data):
                    saved_count += 1
                
                # ä¿å­˜è¯¦ç»†ä¿¡æ¯åˆ°æ‰©å±•è¡¨
                self._save_job_details_with_fingerprint(result, job_id, job_fingerprint, keyword)
            
            self.logger.info(f"æ•°æ®åº“ä¿å­˜å®Œæˆ: æ–°å¢ {saved_count} æ¡ï¼Œè·³è¿‡é‡å¤ {skipped_count} æ¡")
            return True
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    def _create_tables(self, conn: sqlite3.Connection) -> None:
        """
        åˆ›å»ºæ•°æ®åº“è¡¨ï¼ˆåŸºäºCLAUDE.mdä¸­çš„å®šä¹‰ï¼ŒåŒ…å«job_fingerprintå­—æ®µï¼‰
        
        Args:
            conn: æ•°æ®åº“è¿æ¥
        """
        cursor = conn.cursor()
        
        # åˆ›å»ºèŒä½è¡¨ï¼ˆæŒ‰ç…§CLAUDE.mdä¸­çš„å®šä¹‰ï¼ŒåŒ…å«æŒ‡çº¹å­—æ®µï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS jobs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                job_id VARCHAR(100) UNIQUE NOT NULL,
                title VARCHAR(200) NOT NULL,
                company VARCHAR(200) NOT NULL,
                url VARCHAR(500) NOT NULL,
                job_fingerprint VARCHAR(12) UNIQUE,
                application_status VARCHAR(50) DEFAULT 'pending',
                match_score FLOAT,
                website VARCHAR(50) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                submitted_at TIMESTAMP
            )
        """)
        
        # åˆ›å»ºæ‰©å±•ä¿¡æ¯è¡¨ï¼ˆå­˜å‚¨é¢å¤–çš„èŒä½ä¿¡æ¯ï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS job_details (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                job_id VARCHAR(100) NOT NULL,
                salary TEXT,
                location TEXT,
                experience TEXT,
                education TEXT,
                description TEXT,
                requirements TEXT,
                benefits TEXT,
                publish_time TEXT,
                company_scale TEXT,
                industry TEXT,
                keyword TEXT,
                extracted_at TEXT,
                FOREIGN KEY (job_id) REFERENCES jobs (job_id)
            )
        """)
        
        # åˆ›å»ºæœç´¢å†å²è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS search_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                keyword TEXT NOT NULL,
                results_count INTEGER,
                search_time DATETIME DEFAULT CURRENT_TIMESTAMP,
                file_path TEXT
            )
        """)
        
        # åˆ›å»ºç´¢å¼•ï¼ˆåŒ…å«æŒ‡çº¹ç´¢å¼•ï¼‰
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_jobs_job_id ON jobs(job_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_jobs_company ON jobs(company)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_jobs_website ON jobs(website)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_jobs_fingerprint ON jobs(job_fingerprint)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_job_details_job_id ON job_details(job_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_job_details_keyword ON job_details(keyword)")
        
        conn.commit()
    
    def _generate_job_id(self, url: str, title: str, company: str) -> str:
        """
        ç”ŸæˆèŒä½å”¯ä¸€æ ‡è¯†
        
        Args:
            url: èŒä½URL
            title: èŒä½æ ‡é¢˜
            company: å…¬å¸åç§°
            
        Returns:
            èŒä½ID
        """
        # ä¼˜å…ˆä»URLä¸­æå–ID
        if url:
            import re
            match = re.search(r'/(\d+)\.html?', url)
            if match:
                return f"qc_{match.group(1)}"
            
            match = re.search(r'jobid[=:](\d+)', url, re.IGNORECASE)
            if match:
                return f"qc_{match.group(1)}"
        
        # å¦‚æœæ— æ³•ä»URLæå–ï¼Œåˆ™åŸºäºæ ‡é¢˜å’Œå…¬å¸ç”Ÿæˆå“ˆå¸Œ
        content = f"{title}_{company}_{url}"
        hash_obj = hashlib.md5(content.encode('utf-8'))
        return f"qc_{hash_obj.hexdigest()[:12]}"
    
    def save_job_details(self, results: List[Dict[str, Any]], keyword: str) -> bool:
        """
        ä¿å­˜èŒä½è¯¦ç»†ä¿¡æ¯åˆ°æ‰©å±•è¡¨
        
        Args:
            results: èŒä½è¯¦ç»†ä¿¡æ¯åˆ—è¡¨
            keyword: æœç´¢å…³é”®è¯
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                for result in results:
                    job_url = result.get('url', '')
                    job_id = self._generate_job_id(job_url, result.get('title', ''), result.get('company', ''))
                    
                    # æ’å…¥æˆ–æ›´æ–°èŒä½è¯¦ç»†ä¿¡æ¯
                    cursor.execute("""
                        INSERT OR REPLACE INTO job_details (
                            job_id, salary, location, experience, education,
                            description, requirements, benefits, publish_time,
                            company_scale, industry, keyword, extracted_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        job_id,
                        result.get('salary', ''),
                        result.get('location', ''),
                        result.get('experience', ''),
                        result.get('education', ''),
                        result.get('description', ''),
                        result.get('requirements', ''),
                        result.get('benefits', ''),
                        result.get('publish_time', ''),
                        result.get('company_scale', ''),
                        result.get('industry', ''),
                        keyword,
                        result.get('extracted_at', datetime.now().isoformat())
                    ))
                
                conn.commit()
                self.logger.debug(f"èŒä½è¯¦ç»†ä¿¡æ¯å·²ä¿å­˜ {len(results)} æ¡è®°å½•")
                return True
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜èŒä½è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
            return False
    
    def _sanitize_filename(self, filename: str) -> str:
        """
        æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦
        
        Args:
            filename: åŸå§‹æ–‡ä»¶å
            
        Returns:
            æ¸…ç†åçš„æ–‡ä»¶å
        """
        import re
        # ç§»é™¤æˆ–æ›¿æ¢éæ³•å­—ç¬¦
        sanitized = re.sub(r'[<>:"/\\|?*]', '_', filename)
        # é™åˆ¶é•¿åº¦
        return sanitized[:50] if len(sanitized) > 50 else sanitized
    
    def load_search_results(self, filepath: str) -> Optional[Dict[str, Any]]:
        """
        åŠ è½½æœç´¢ç»“æœ
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æœç´¢ç»“æœæ•°æ®
        """
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.logger.info(f"ğŸ“‚ æœç´¢ç»“æœå·²åŠ è½½: {filepath}")
            return data
            
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½æœç´¢ç»“æœå¤±è´¥: {e}")
            return None
    
    def query_jobs(self, 
                   keyword: Optional[str] = None,
                   company: Optional[str] = None,
                   location: Optional[str] = None,
                   status: Optional[str] = None,
                   limit: int = 100) -> List[Dict[str, Any]]:
        """
        æŸ¥è¯¢èŒä½æ•°æ®
        
        Args:
            keyword: å…³é”®è¯è¿‡æ»¤
            company: å…¬å¸åè¿‡æ»¤
            location: åœ°ç‚¹è¿‡æ»¤
            status: çŠ¶æ€è¿‡æ»¤
            limit: ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            èŒä½æ•°æ®åˆ—è¡¨
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row  # è¿”å›å­—å…¸æ ¼å¼
                cursor = conn.cursor()
                
                # æ„å»ºæŸ¥è¯¢æ¡ä»¶
                conditions = []
                params = []
                
                if keyword:
                    conditions.append("(j.title LIKE ? OR jd.keyword LIKE ?)")
                    params.extend([f"%{keyword}%", f"%{keyword}%"])
                
                if company:
                    conditions.append("j.company LIKE ?")
                    params.append(f"%{company}%")
                
                if location:
                    conditions.append("jd.location LIKE ?")
                    params.append(f"%{location}%")
                
                if status:
                    conditions.append("j.application_status = ?")
                    params.append(status)
                
                # æ„å»ºSQLæŸ¥è¯¢ï¼ˆè”åˆæŸ¥è¯¢ä¸»è¡¨å’Œè¯¦æƒ…è¡¨ï¼‰
                sql = """
                    SELECT j.*, jd.salary, jd.location, jd.experience, jd.education,
                           jd.description, jd.requirements, jd.benefits, jd.publish_time,
                           jd.company_scale, jd.industry, jd.keyword
                    FROM jobs j
                    LEFT JOIN job_details jd ON j.job_id = jd.job_id
                """
                
                if conditions:
                    sql += " WHERE " + " AND ".join(conditions)
                sql += " ORDER BY j.created_at DESC LIMIT ?"
                params.append(limit)
                
                cursor.execute(sql, params)
                rows = cursor.fetchall()
                
                # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                results = [dict(row) for row in rows]
                
                self.logger.info(f"ğŸ“Š æŸ¥è¯¢åˆ° {len(results)} æ¡èŒä½è®°å½•")
                return results
                
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è¯¢èŒä½æ•°æ®å¤±è´¥: {e}")
            return []
    
    def get_search_statistics(self) -> Dict[str, Any]:
        """
        è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # æ€»èŒä½æ•°
                cursor.execute("SELECT COUNT(*) FROM jobs")
                total_jobs = cursor.fetchone()[0]
                
                # æŒ‰ç½‘ç«™ç»Ÿè®¡
                cursor.execute("""
                    SELECT website, COUNT(*) as count 
                    FROM jobs 
                    GROUP BY website 
                    ORDER BY count DESC
                """)
                website_stats = cursor.fetchall()
                
                # æŒ‰çŠ¶æ€ç»Ÿè®¡
                cursor.execute("""
                    SELECT application_status, COUNT(*) as count 
                    FROM jobs 
                    GROUP BY application_status 
                    ORDER BY count DESC
                """)
                status_stats = cursor.fetchall()
                
                # æŒ‰å…¬å¸ç»Ÿè®¡ï¼ˆå‰10ï¼‰
                cursor.execute("""
                    SELECT company, COUNT(*) as count 
                    FROM jobs 
                    WHERE company != '' 
                    GROUP BY company 
                    ORDER BY count DESC 
                    LIMIT 10
                """)
                company_stats = cursor.fetchall()
                
                # æŒ‰å…³é”®è¯ç»Ÿè®¡ï¼ˆå‰10ï¼‰
                cursor.execute("""
                    SELECT keyword, COUNT(*) as count 
                    FROM job_details 
                    WHERE keyword != '' 
                    GROUP BY keyword 
                    ORDER BY count DESC 
                    LIMIT 10
                """)
                keyword_stats = cursor.fetchall()
                
                return {
                    'total_jobs': total_jobs,
                    'website_stats': website_stats,
                    'status_stats': status_stats,
                    'company_stats': company_stats,
                    'keyword_stats': keyword_stats,
                    'generated_at': datetime.now().isoformat()
                }
                
        except Exception as e:
            self.logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def update_job_status(self, job_id: str, status: str, submitted_at: Optional[str] = None) -> bool:
        """
        æ›´æ–°èŒä½çŠ¶æ€
        
        Args:
            job_id: èŒä½ID
            status: æ–°çŠ¶æ€
            submitted_at: æŠ•é€’æ—¶é—´
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                if submitted_at:
                    cursor.execute("""
                        UPDATE jobs 
                        SET application_status = ?, submitted_at = ? 
                        WHERE job_id = ?
                    """, (status, submitted_at, job_id))
                else:
                    cursor.execute("""
                        UPDATE jobs 
                        SET application_status = ? 
                        WHERE job_id = ?
                    """, (status, job_id))
                
                conn.commit()
                
                if cursor.rowcount > 0:
                    self.logger.info(f"èŒä½çŠ¶æ€å·²æ›´æ–°: {job_id} -> {status}")
                    return True
                else:
                    self.logger.warning(f"æœªæ‰¾åˆ°èŒä½: {job_id}")
                    return False
                    
        except Exception as e:
            self.logger.error(f"æ›´æ–°èŒä½çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def list_saved_files(self, directory: str = "search_results") -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºä¿å­˜çš„æ–‡ä»¶
        
        Args:
            directory: ç›®å½•å ('search_results' æˆ– 'job_details')
            
        Returns:
            æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
        """
        try:
            if directory == "search_results":
                target_dir = self.search_results_dir
            elif directory == "job_details":
                target_dir = self.job_details_dir
            else:
                target_dir = self.data_dir / directory
            
            if not target_dir.exists():
                return []
            
            files = []
            for file_path in target_dir.glob("*.json"):
                try:
                    stat = file_path.stat()
                    files.append({
                        'filename': file_path.name,
                        'filepath': str(file_path),
                        'size': stat.st_size,
                        'modified_time': datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        'created_time': datetime.fromtimestamp(stat.st_ctime).isoformat()
                    })
                except Exception as e:
                    self.logger.warning(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {file_path}: {e}")
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
            files.sort(key=lambda x: x['modified_time'], reverse=True)
            
            return files
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def _save_job_details_with_fingerprint(self, result: Dict, job_id: str, job_fingerprint: str, keyword: str) -> bool:
        """
        ä¿å­˜èŒä½è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«æŒ‡çº¹ï¼‰
        
        Args:
            result: èŒä½è¯¦ç»†ä¿¡æ¯
            job_id: èŒä½ID
            job_fingerprint: èŒä½æŒ‡çº¹
            keyword: æœç´¢å…³é”®è¯
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # å…ˆæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤æ’å…¥
                cursor.execute("SELECT id FROM job_details WHERE job_id = ?", (job_id,))
                existing_record = cursor.fetchone()
                
                if existing_record:
                    # æ›´æ–°ç°æœ‰è®°å½•
                    cursor.execute("""
                        UPDATE job_details SET
                            salary = ?, location = ?, experience = ?, education = ?,
                            description = ?, requirements = ?, benefits = ?, publish_time = ?,
                            company_scale = ?, industry = ?, keyword = ?, extracted_at = ?
                        WHERE job_id = ?
                    """, (
                        result.get('salary', ''),
                        result.get('location', ''),
                        result.get('experience', ''),
                        result.get('education', ''),
                        result.get('description', ''),
                        result.get('requirements', ''),
                        result.get('benefits', ''),
                        result.get('publish_time', ''),
                        result.get('company_scale', ''),
                        result.get('industry', ''),
                        keyword,
                        result.get('extracted_at', datetime.now().isoformat()),
                        job_id
                    ))
                else:
                    # æ’å…¥æ–°è®°å½•
                    cursor.execute("""
                        INSERT INTO job_details (
                            job_id, salary, location, experience, education,
                            description, requirements, benefits, publish_time,
                            company_scale, industry, keyword, extracted_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                    job_id,
                    result.get('salary', ''),
                    result.get('location', ''),
                    result.get('experience', ''),
                    result.get('education', ''),
                    result.get('description', ''),
                    result.get('requirements', ''),
                    result.get('benefits', ''),
                    result.get('publish_time', ''),
                    result.get('company_scale', ''),
                    result.get('industry', ''),
                    keyword,
                    result.get('extracted_at', datetime.now().isoformat())
                ))
                
                conn.commit()
                return True
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜èŒä½è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
            return False
    
    def save_job_detail(self, detail_data: Dict[str, Any], job_url: str) -> bool:
        """
        ä¿å­˜å•ä¸ªèŒä½è¯¦æƒ…åˆ°æ•°æ®åº“ï¼ˆæ›¿ä»£JSONæ–‡ä»¶ä¿å­˜ï¼‰
        
        Args:
            detail_data: èŒä½è¯¦æƒ…æ•°æ®
            job_url: èŒä½URL
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            # ä½¿ç”¨DatabaseManager
            db_manager = DatabaseManager(self.db_path)
            db_manager.init_database()
            
            # ç”Ÿæˆjob_idå’ŒæŒ‡çº¹
            job_id = self._generate_job_id(
                job_url,
                detail_data.get('title', ''),
                detail_data.get('company', '')
            )
            
            # ä»è¯¦æƒ…æ•°æ®ä¸­æå–åŸºæœ¬ä¿¡æ¯ç”ŸæˆæŒ‡çº¹
            job_fingerprint = generate_job_fingerprint(
                detail_data.get('title', ''),
                detail_data.get('company', ''),
                detail_data.get('salary', ''),
                detail_data.get('location', '')
            )
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if db_manager.fingerprint_exists(job_fingerprint):
                self.logger.debug(f"èŒä½è¯¦æƒ…å·²å­˜åœ¨ï¼Œè·³è¿‡ä¿å­˜: {detail_data.get('title', '')}")
                return True
            
            # å‡†å¤‡èŒä½æ•°æ®
            job_data = {
                'job_id': job_id,
                'title': detail_data.get('title', ''),
                'company': detail_data.get('company', ''),
                'url': job_url,
                'job_fingerprint': job_fingerprint,
                'application_status': 'pending',
                'match_score': None,
                'website': 'qiancheng',
                'created_at': datetime.now().isoformat(),
                'submitted_at': None
            }
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            success = db_manager.save_job(job_data)
            
            if success:
                # ä¿å­˜è¯¦ç»†ä¿¡æ¯
                self._save_job_details_with_fingerprint(detail_data, job_id, job_fingerprint, "detail_extraction")
                self.logger.info(f"èŒä½è¯¦æƒ…å·²ä¿å­˜åˆ°æ•°æ®åº“: {detail_data.get('title', '')}")
            
            return success
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜èŒä½è¯¦æƒ…å¤±è´¥: {e}")
            return False
    
    def update_job_url(self, job_id: str, job_url: str) -> bool:
        """
        æ›´æ–°èŒä½çš„URL
        
        Args:
            job_id: èŒä½ID
            job_url: èŒä½URL
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            db_manager = DatabaseManager(self.db_path)
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    UPDATE jobs
                    SET url = ?
                    WHERE job_id = ?
                """, (job_url, job_id))
                
                conn.commit()
                
                if cursor.rowcount > 0:
                    self.logger.debug(f"èŒä½URLå·²æ›´æ–°: {job_id} -> {job_url}")
                    return True
                else:
                    self.logger.warning(f"æœªæ‰¾åˆ°èŒä½è¿›è¡ŒURLæ›´æ–°: {job_id}")
                    return False
                    
        except Exception as e:
            self.logger.error(f"æ›´æ–°èŒä½URLå¤±è´¥: {e}")
            return False
    
    def update_job_with_detail_url(self, title: str, company: str, detail_url: str) -> bool:
        """
        æ ¹æ®æ ‡é¢˜å’Œå…¬å¸åç§°æ›´æ–°èŒä½çš„è¯¦æƒ…URL
        
        Args:
            title: èŒä½æ ‡é¢˜
            company: å…¬å¸åç§°
            detail_url: è¯¦æƒ…é¡µURL
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            db_manager = DatabaseManager(self.db_path)
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # æŸ¥æ‰¾åŒ¹é…çš„èŒä½è®°å½•
                cursor.execute("""
                    SELECT job_id FROM jobs
                    WHERE title = ? AND company = ? AND (url = '' OR url IS NULL)
                    ORDER BY created_at DESC
                    LIMIT 1
                """, (title, company))
                
                result = cursor.fetchone()
                if result:
                    job_id = result[0]
                    
                    # æ›´æ–°URL
                    cursor.execute("""
                        UPDATE jobs
                        SET url = ?
                        WHERE job_id = ?
                    """, (detail_url, job_id))
                    
                    conn.commit()
                    
                    if cursor.rowcount > 0:
                        self.logger.info(f"èŒä½URLå·²æ›´æ–°: {title} @ {company} -> {detail_url}")
                        return True
                
                self.logger.warning(f"æœªæ‰¾åˆ°åŒ¹é…çš„èŒä½è®°å½•: {title} @ {company}")
                return False
                    
        except Exception as e:
            self.logger.error(f"æ›´æ–°èŒä½è¯¦æƒ…URLå¤±è´¥: {e}")
            return False
    
    def check_job_fingerprint_exists(self, title: str, company: str, salary: str = "", location: str = "") -> bool:
        """
        æ£€æŸ¥èŒä½æŒ‡çº¹æ˜¯å¦å·²å­˜åœ¨
        
        Args:
            title: èŒä½æ ‡é¢˜
            company: å…¬å¸åç§°
            salary: è–ªèµ„ä¿¡æ¯
            location: å·¥ä½œåœ°ç‚¹
            
        Returns:
            æ˜¯å¦å·²å­˜åœ¨
        """
        try:
            fingerprint = generate_job_fingerprint(title, company, salary, location)
            db_manager = DatabaseManager(self.db_path)
            return db_manager.fingerprint_exists(fingerprint)
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥èŒä½æŒ‡çº¹å¤±è´¥: {e}")
            return False
    
    def get_deduplication_stats(self) -> Dict[str, Any]:
        """
        è·å–å»é‡ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            å»é‡ç»Ÿè®¡æ•°æ®
        """
        try:
            db_manager = DatabaseManager(self.db_path)
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # æ€»èŒä½æ•°
                cursor.execute("SELECT COUNT(*) FROM jobs")
                total_jobs = cursor.fetchone()[0]
                
                # æœ‰æŒ‡çº¹çš„èŒä½æ•°
                cursor.execute("SELECT COUNT(*) FROM jobs WHERE job_fingerprint IS NOT NULL")
                jobs_with_fingerprint = cursor.fetchone()[0]
                
                # å”¯ä¸€æŒ‡çº¹æ•°
                cursor.execute("SELECT COUNT(DISTINCT job_fingerprint) FROM jobs WHERE job_fingerprint IS NOT NULL")
                unique_fingerprints = cursor.fetchone()[0]
                
                # é‡å¤èŒä½æ•°
                duplicate_count = db_manager.get_duplicate_jobs_count()
                
                return {
                    'total_jobs': total_jobs,
                    'jobs_with_fingerprint': jobs_with_fingerprint,
                    'unique_fingerprints': unique_fingerprints,
                    'duplicate_jobs': duplicate_count,
                    'deduplication_rate': (duplicate_count / max(total_jobs, 1)) * 100,
                    'generated_at': datetime.now().isoformat()
                }
                
        except Exception as e:
            self.logger.error(f"è·å–å»é‡ç»Ÿè®¡å¤±è´¥: {e}")
            return {}