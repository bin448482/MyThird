"""
å‘é‡æ•°æ®åº“å†…å®¹æµ‹è¯•è„šæœ¬

ç”¨äºéªŒè¯å‘é‡æ•°æ®åº“çš„å†…å®¹æ˜¯å¦è¾¾åˆ°é¢„æœŸï¼ŒåŒ…æ‹¬ï¼š
1. æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
2. æ–‡æ¡£å†…å®¹æ£€æŸ¥
3. æœç´¢åŠŸèƒ½æµ‹è¯•
4. å…ƒæ•°æ®éªŒè¯
5. ç›¸ä¼¼åº¦æµ‹è¯•
"""

import yaml
import json
from datetime import datetime
from typing import List, Dict, Any
from src.rag.vector_manager import ChromaDBManager
from src.rag.rag_system_coordinator import RAGSystemCoordinator


class VectorDatabaseTester:
    """å‘é‡æ•°æ®åº“æµ‹è¯•å™¨"""
    
    def __init__(self, config_path: str = 'config/test_config.yaml'):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.load_config()
        self.init_vector_manager()
        
    def load_config(self):
        """åŠ è½½é…ç½®"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
            print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ: {self.config_path}")
        except Exception as e:
            print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def init_vector_manager(self):
        """åˆå§‹åŒ–å‘é‡ç®¡ç†å™¨"""
        try:
            vector_config = self.config.get('vector_store', {})
            self.vector_manager = ChromaDBManager(vector_config)
            print(f"âœ… å‘é‡ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ å‘é‡ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def test_database_stats(self) -> Dict[str, Any]:
        """æµ‹è¯•æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*50)
        print("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯æµ‹è¯•")
        print("="*50)
        
        try:
            stats = self.vector_manager.get_collection_stats()
            
            print(f"ğŸ“‹ é›†åˆåç§°: {stats.get('collection_name', 'unknown')}")
            print(f"ğŸ“ å­˜å‚¨è·¯å¾„: {stats.get('persist_directory', 'unknown')}")
            print(f"ğŸ“„ æ–‡æ¡£æ•°é‡: {stats.get('document_count', 0)}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£
            if stats.get('document_count', 0) > 0:
                print("âœ… æ•°æ®åº“åŒ…å«æ–‡æ¡£")
                return {"status": "success", "stats": stats}
            else:
                print("âš ï¸ æ•°æ®åº“ä¸ºç©º")
                return {"status": "empty", "stats": stats}
                
        except Exception as e:
            print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}
    
    def test_document_content(self, sample_size: int = 5) -> Dict[str, Any]:
        """æµ‹è¯•æ–‡æ¡£å†…å®¹"""
        print("\n" + "="*50)
        print("ğŸ“ æ–‡æ¡£å†…å®¹æµ‹è¯•")
        print("="*50)
        
        try:
            # è·å–æ ·æœ¬æ–‡æ¡£
            collection = self.vector_manager.vectorstore._collection
            all_data = collection.get(limit=sample_size)
            
            if not all_data['ids']:
                print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡æ¡£")
                return {"status": "empty", "documents": []}
            
            documents = []
            for i, doc_id in enumerate(all_data['ids']):
                doc_info = {
                    "id": doc_id,
                    "content": all_data['documents'][i][:200] + "..." if len(all_data['documents'][i]) > 200 else all_data['documents'][i],
                    "metadata": all_data['metadatas'][i] if all_data['metadatas'] else {},
                    "content_length": len(all_data['documents'][i])
                }
                documents.append(doc_info)
                
                print(f"\nğŸ“„ æ–‡æ¡£ {i+1}:")
                print(f"   ID: {doc_id}")
                print(f"   å†…å®¹é•¿åº¦: {doc_info['content_length']} å­—ç¬¦")
                print(f"   å†…å®¹é¢„è§ˆ: {doc_info['content']}")
                print(f"   å…ƒæ•°æ®: {doc_info['metadata']}")
            
            print(f"\nâœ… æˆåŠŸæ£€æŸ¥ {len(documents)} ä¸ªæ–‡æ¡£")
            return {"status": "success", "documents": documents}
            
        except Exception as e:
            print(f"âŒ æ–‡æ¡£å†…å®¹æ£€æŸ¥å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}
    
    def test_search_functionality(self, test_queries: List[str] = None) -> Dict[str, Any]:
        """æµ‹è¯•æœç´¢åŠŸèƒ½"""
        print("\n" + "="*50)
        print("ğŸ” æœç´¢åŠŸèƒ½æµ‹è¯•")
        print("="*50)
        
        if test_queries is None:
            test_queries = [
                "Pythonå¼€å‘å·¥ç¨‹å¸ˆ",
                "å‰ç«¯å¼€å‘",
                "æ•°æ®åˆ†æå¸ˆ",
                "æœºå™¨å­¦ä¹ ",
                "è½¯ä»¶å·¥ç¨‹å¸ˆ"
            ]
        
        search_results = {}
        
        for query in test_queries:
            try:
                print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: '{query}'")
                
                # åŸºç¡€æœç´¢
                results = self.vector_manager.search_similar_jobs(query, k=3)
                print(f"   åŸºç¡€æœç´¢ç»“æœ: {len(results)} ä¸ªæ–‡æ¡£")
                
                # å¸¦åˆ†æ•°æœç´¢
                scored_results = self.vector_manager.similarity_search_with_score(query, k=3)
                print(f"   å¸¦åˆ†æ•°æœç´¢ç»“æœ: {len(scored_results)} ä¸ªæ–‡æ¡£")
                
                # æ˜¾ç¤ºå‰3ä¸ªç»“æœ
                for i, (doc, score) in enumerate(scored_results[:3], 1):
                    print(f"   ç»“æœ {i}: ç›¸ä¼¼åº¦={score:.3f}, ç±»å‹={doc.metadata.get('document_type', 'æœªçŸ¥')}")
                    print(f"           å†…å®¹é¢„è§ˆ: {doc.page_content[:100]}...")
                
                search_results[query] = {
                    "basic_count": len(results),
                    "scored_count": len(scored_results),
                    "top_scores": [score for _, score in scored_results[:3]]
                }
                
            except Exception as e:
                print(f"   âŒ æŸ¥è¯¢å¤±è´¥: {e}")
                search_results[query] = {"error": str(e)}
        
        print(f"\nâœ… æœç´¢åŠŸèƒ½æµ‹è¯•å®Œæˆ")
        return {"status": "success", "results": search_results}
    
    def test_metadata_validation(self) -> Dict[str, Any]:
        """æµ‹è¯•å…ƒæ•°æ®éªŒè¯"""
        print("\n" + "="*50)
        print("ğŸ·ï¸ å…ƒæ•°æ®éªŒè¯æµ‹è¯•")
        print("="*50)
        
        try:
            collection = self.vector_manager.vectorstore._collection
            all_data = collection.get()
            
            if not all_data['metadatas']:
                print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å…ƒæ•°æ®")
                return {"status": "no_metadata"}
            
            # ç»Ÿè®¡å…ƒæ•°æ®å­—æ®µ
            field_stats = {}
            job_ids = set()
            document_types = set()
            
            for metadata in all_data['metadatas']:
                if metadata:
                    for key, value in metadata.items():
                        if key not in field_stats:
                            field_stats[key] = {"count": 0, "sample_values": set()}
                        field_stats[key]["count"] += 1
                        if len(field_stats[key]["sample_values"]) < 5:
                            field_stats[key]["sample_values"].add(str(value)[:50])
                    
                    # æ”¶é›†ç‰¹å®šå­—æ®µ
                    if 'job_id' in metadata:
                        job_ids.add(metadata['job_id'])
                    if 'document_type' in metadata:
                        document_types.add(metadata['document_type'])
            
            print(f"ğŸ“Š å…ƒæ•°æ®å­—æ®µç»Ÿè®¡:")
            for field, stats in field_stats.items():
                sample_values = list(stats["sample_values"])[:3]
                print(f"   {field}: {stats['count']} ä¸ªæ–‡æ¡£, æ ·æœ¬å€¼: {sample_values}")
            
            print(f"\nğŸ“‹ èŒä½IDæ•°é‡: {len(job_ids)}")
            print(f"ğŸ“‹ æ–‡æ¡£ç±»å‹: {list(document_types)}")
            
            validation_result = {
                "status": "success",
                "field_stats": {k: {"count": v["count"], "sample_values": list(v["sample_values"])} 
                               for k, v in field_stats.items()},
                "unique_job_ids": len(job_ids),
                "document_types": list(document_types)
            }
            
            print(f"âœ… å…ƒæ•°æ®éªŒè¯å®Œæˆ")
            return validation_result
            
        except Exception as e:
            print(f"âŒ å…ƒæ•°æ®éªŒè¯å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}
    
    def test_similarity_quality(self) -> Dict[str, Any]:
        """æµ‹è¯•ç›¸ä¼¼åº¦è´¨é‡"""
        print("\n" + "="*50)
        print("ğŸ¯ ç›¸ä¼¼åº¦è´¨é‡æµ‹è¯•")
        print("="*50)
        
        try:
            # æµ‹è¯•ç”¨ä¾‹ï¼šç›¸å…³å’Œä¸ç›¸å…³çš„æŸ¥è¯¢
            test_cases = [
                {
                    "query": "Pythonå¼€å‘å·¥ç¨‹å¸ˆ",
                    "expected_keywords": ["python", "å¼€å‘", "å·¥ç¨‹å¸ˆ", "ç¼–ç¨‹"],
                    "type": "relevant"
                },
                {
                    "query": "é”€å”®ç»ç†",
                    "expected_keywords": ["é”€å”®", "ç»ç†", "å¸‚åœº"],
                    "type": "relevant"
                },
                {
                    "query": "éšæœºæ— å…³å†…å®¹xyz123",
                    "expected_keywords": [],
                    "type": "irrelevant"
                }
            ]
            
            quality_results = {}
            
            for test_case in test_cases:
                query = test_case["query"]
                print(f"\nğŸ§ª æµ‹è¯•æŸ¥è¯¢: '{query}' ({test_case['type']})")
                
                scored_results = self.vector_manager.similarity_search_with_score(query, k=5)
                
                if scored_results:
                    scores = [score for _, score in scored_results]
                    avg_score = sum(scores) / len(scores)
                    max_score = max(scores)
                    min_score = min(scores)
                    
                    print(f"   å¹³å‡ç›¸ä¼¼åº¦: {avg_score:.3f}")
                    print(f"   æœ€é«˜ç›¸ä¼¼åº¦: {max_score:.3f}")
                    print(f"   æœ€ä½ç›¸ä¼¼åº¦: {min_score:.3f}")
                    
                    # æ£€æŸ¥å…³é”®è¯åŒ¹é…
                    keyword_matches = 0
                    for doc, score in scored_results[:3]:
                        content_lower = doc.page_content.lower()
                        for keyword in test_case["expected_keywords"]:
                            if keyword.lower() in content_lower:
                                keyword_matches += 1
                                break
                    
                    keyword_match_rate = keyword_matches / min(3, len(scored_results)) if scored_results else 0
                    print(f"   å…³é”®è¯åŒ¹é…ç‡: {keyword_match_rate:.2%}")
                    
                    quality_results[query] = {
                        "avg_score": avg_score,
                        "max_score": max_score,
                        "min_score": min_score,
                        "keyword_match_rate": keyword_match_rate,
                        "result_count": len(scored_results)
                    }
                else:
                    print(f"   âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç»“æœ")
                    quality_results[query] = {"result_count": 0}
            
            print(f"\nâœ… ç›¸ä¼¼åº¦è´¨é‡æµ‹è¯•å®Œæˆ")
            return {"status": "success", "results": quality_results}
            
        except Exception as e:
            print(f"âŒ ç›¸ä¼¼åº¦è´¨é‡æµ‹è¯•å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        print("ğŸš€ å¼€å§‹å‘é‡æ•°æ®åº“ç»¼åˆæµ‹è¯•")
        print("="*60)
        
        test_results = {
            "timestamp": datetime.now().isoformat(),
            "config_path": self.config_path,
            "tests": {}
        }
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        test_results["tests"]["stats"] = self.test_database_stats()
        test_results["tests"]["content"] = self.test_document_content()
        test_results["tests"]["search"] = self.test_search_functionality()
        test_results["tests"]["metadata"] = self.test_metadata_validation()
        test_results["tests"]["similarity"] = self.test_similarity_quality()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_test_report(test_results)
        
        print("\n" + "="*60)
        print("ğŸ“‹ æµ‹è¯•æ€»ç»“")
        print("="*60)
        
        success_count = 0
        total_tests = len(test_results["tests"])
        
        for test_name, result in test_results["tests"].items():
            status = result.get("status", "unknown")
            if status == "success":
                print(f"âœ… {test_name}: é€šè¿‡")
                success_count += 1
            elif status == "empty":
                print(f"âš ï¸ {test_name}: æ•°æ®ä¸ºç©º")
            else:
                print(f"âŒ {test_name}: å¤±è´¥")
        
        print(f"\nğŸ“Š æµ‹è¯•é€šè¿‡ç‡: {success_count}/{total_tests} ({success_count/total_tests*100:.1f}%)")
        
        return test_results
    
    def generate_test_report(self, test_results: Dict[str, Any]):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        try:
            report_filename = f"vector_db_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            with open(report_filename, 'w', encoding='utf-8') as f:
                json.dump(test_results, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"\nğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_filename}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æµ‹è¯•æŠ¥å‘Šå¤±è´¥: {e}")
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if hasattr(self, 'vector_manager'):
            self.vector_manager.close()


def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºæµ‹è¯•å™¨
        tester = VectorDatabaseTester()
        
        # è¿è¡Œç»¼åˆæµ‹è¯•
        results = tester.run_comprehensive_test()
        
        # å…³é—­è¿æ¥
        tester.close()
        
        print("\nğŸ‰ å‘é‡æ•°æ®åº“æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()