#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–çš„JobProcessoråŠŸèƒ½
"""

import sys
import asyncio
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from src.rag.optimized_job_processor import OptimizedJobProcessor
from src.rag.database_job_reader import DatabaseJobReader

def test_optimized_job_processor():
    """æµ‹è¯•ä¼˜åŒ–çš„èŒä½å¤„ç†å™¨"""
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("ğŸ§ª æµ‹è¯•OptimizedJobProcessoråŠŸèƒ½")
    print("=" * 50)
    
    async def run_tests():
        try:
            # åˆå§‹åŒ–ç»„ä»¶
            llm_config = {
                'provider': 'zhipu',
                'model': 'glm-4-flash',
                'api_key': 'your-api-key-here',  # å®é™…ä½¿ç”¨æ—¶éœ€è¦é…ç½®
                'temperature': 0.1,
                'max_tokens': 1500
            }
            
            processor = OptimizedJobProcessor(llm_config=llm_config)
            print("âœ… OptimizedJobProcessoråˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–æ•°æ®åº“è¯»å–å™¨
            db_reader = DatabaseJobReader("./data/jobs.db")
            print("âœ… DatabaseJobReaderåˆå§‹åŒ–æˆåŠŸ")
            
            # æµ‹è¯•1: è·å–æµ‹è¯•æ•°æ®
            print("\nğŸ“Š æµ‹è¯•1: è·å–æµ‹è¯•æ•°æ®")
            test_jobs = db_reader.get_jobs_for_rag_processing(limit=2)
            print(f"   è·å–åˆ° {len(test_jobs)} ä¸ªæµ‹è¯•èŒä½")
            
            if not test_jobs:
                print("âŒ æ²¡æœ‰å¯æµ‹è¯•çš„èŒä½æ•°æ®")
                return False
            
            # æµ‹è¯•2: å¤„ç†èŒä½æ•°æ®ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼Œä¸å®é™…è°ƒç”¨LLMï¼‰
            print("\nğŸ”„ æµ‹è¯•2: èŒä½æ•°æ®å¤„ç†ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰")
            for i, job_data in enumerate(test_jobs[:2], 1):
                print(f"\n   å¤„ç†èŒä½ {i}: {job_data.get('title', 'æ— æ ‡é¢˜')}")
                print(f"      å…¬å¸: {job_data.get('company', 'æ— å…¬å¸')}")
                print(f"      è–ªèµ„: {job_data.get('salary', 'æ— è–ªèµ„ä¿¡æ¯')}")
                print(f"      æè¿°é•¿åº¦: {len(job_data.get('description', '') or '')}")
                print(f"      è¦æ±‚é•¿åº¦: {len(job_data.get('requirements', '') or '')}")
                
                # æ¨¡æ‹Ÿå¤„ç†ç»“æœï¼ˆä¸å®é™…è°ƒç”¨LLMï¼‰
                mock_job_structure = processor._fallback_extraction_from_db(job_data)
                print(f"      å¤„ç†ç»“æœ: {mock_job_structure.job_title} - {mock_job_structure.company}")
                
                # æµ‹è¯•æ–‡æ¡£åˆ›å»º
                documents = processor.create_documents(
                    mock_job_structure, 
                    job_id=job_data.get('job_id'),
                    job_url=job_data.get('url')
                )
                print(f"      åˆ›å»ºæ–‡æ¡£æ•°: {len(documents)}")
                
                # æ˜¾ç¤ºæ–‡æ¡£ç±»å‹
                doc_types = [doc.metadata.get('type') for doc in documents]
                print(f"      æ–‡æ¡£ç±»å‹: {', '.join(doc_types)}")
                
                # éªŒè¯èŒä½ç»“æ„
                is_valid = processor.validate_job_structure(mock_job_structure)
                print(f"      ç»“æ„æœ‰æ•ˆæ€§: {'âœ… æœ‰æ•ˆ' if is_valid else 'âŒ æ— æ•ˆ'}")
                
                # è·å–å¤„ç†ç»Ÿè®¡
                stats = processor.get_processing_stats(mock_job_structure)
                print(f"      å¤„ç†ç»Ÿè®¡: èŒè´£{stats['responsibilities_count']}ä¸ª, è¦æ±‚{stats['requirements_count']}ä¸ª, æŠ€èƒ½{stats['skills_count']}ä¸ª")
            
            # æµ‹è¯•3: å­—æ®µæ˜ å°„éªŒè¯
            print("\nğŸ” æµ‹è¯•3: å­—æ®µæ˜ å°„éªŒè¯")
            sample_job = test_jobs[0]
            
            # ç›´æ¥æ˜ å°„å­—æ®µæµ‹è¯•
            direct_fields = {
                'title': sample_job.get('title'),
                'company': sample_job.get('company'),
                'location': sample_job.get('location'),
                'education': sample_job.get('education'),
                'experience': sample_job.get('experience'),
                'company_scale': sample_job.get('company_scale')
            }
            
            print("   ç›´æ¥æ˜ å°„å­—æ®µ:")
            for field, value in direct_fields.items():
                status = "âœ…" if value else "âš ï¸"
                print(f"      {field}: {status} {value or 'ç©ºå€¼'}")
            
            # LLMå¤„ç†å­—æ®µæµ‹è¯•
            llm_fields = {
                'salary': sample_job.get('salary'),
                'description': len(sample_job.get('description', '') or ''),
                'requirements': len(sample_job.get('requirements', '') or '')
            }
            
            print("   LLMå¤„ç†å­—æ®µ:")
            for field, value in llm_fields.items():
                if field in ['description', 'requirements']:
                    status = "âœ…" if value > 0 else "âš ï¸"
                    print(f"      {field}: {status} {value} å­—ç¬¦")
                else:
                    status = "âœ…" if value else "âš ï¸"
                    print(f"      {field}: {status} {value or 'ç©ºå€¼'}")
            
            # æµ‹è¯•4: è¯­ä¹‰åˆ†å‰²æµ‹è¯•
            print("\nğŸ“ æµ‹è¯•4: è¯­ä¹‰åˆ†å‰²æµ‹è¯•")
            test_text = sample_job.get('description', '')
            if test_text:
                chunks = processor.split_text_semantically(test_text[:500])  # åªæµ‹è¯•å‰500å­—ç¬¦
                print(f"   åŸæ–‡é•¿åº¦: {len(test_text)} å­—ç¬¦")
                print(f"   åˆ†å‰²å—æ•°: {len(chunks)}")
                print(f"   å¹³å‡å—é•¿åº¦: {sum(len(chunk) for chunk in chunks) // len(chunks) if chunks else 0} å­—ç¬¦")
            else:
                print("   âš ï¸ æ²¡æœ‰æè¿°æ–‡æœ¬å¯ä¾›åˆ†å‰²æµ‹è¯•")
            
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
            return True
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    return asyncio.run(run_tests())

if __name__ == "__main__":
    success = test_optimized_job_processor()
    sys.exit(0 if success else 1)