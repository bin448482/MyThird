#!/usr/bin/env python3
"""
å¿«é€Ÿè°ƒè¯• ContentExtractor.extract_from_keyword æ–¹æ³•
ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½æµ‹è¯•
"""

import sys
import time
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def quick_test():
    """å¿«é€Ÿæµ‹è¯• extract_from_keyword æ–¹æ³•"""
    
    # è®¾ç½®ç®€å•æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    # æœ€å°é…ç½®
    config = {
        'search': {
            'base_url': 'https://we.51job.com/pc/search',
            'job_area': '020000',
            'search_type': '2',
            'keyword_type': '',
            'strategy': {'max_pages': 1, 'page_delay': 1}
        },
        'selectors': {
            'search_page': {
                'job_list': '.joblist',
                'job_title': '.jname a',
                'company_name': '.cname',
                'salary': '.sal',
                'location': '.area',
                'next_page': '.btn-next'
            }
        },
        'selenium': {
            'headless': False,
            'window_size': '1920,1080',
            'page_load_timeout': 30,
            'element_wait_timeout': 10,
            'implicit_wait': 5
        },
        'mode': {
            'development': True,
            'debug': True,
            'skip_login': True,
            'close_on_complete': True
        },
        'database': {'enabled': True, 'path': './data/debug_jobs.db'}
    }
    
    print("ğŸš€ å¼€å§‹å¿«é€Ÿè°ƒè¯•æµ‹è¯•...")
    print(f"â° å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S')}")
    
    try:
        from src.extraction.content_extractor import ContentExtractor
        
        # åˆ›å»ºæå–å™¨
        extractor = ContentExtractor(config)
        
        # æµ‹è¯•å‚æ•°
        keyword = "Pythonå¼€å‘"
        max_results = 5  # åªæµ‹è¯•5ä¸ªèŒä½
        max_pages = 1    # åªæµ‹è¯•1é¡µ
        extract_details = False  # å…ˆä¸æå–è¯¦æƒ…ï¼Œæµ‹è¯•åŸºç¡€åŠŸèƒ½
        
        print(f"ğŸ“Š æµ‹è¯•å‚æ•°: å…³é”®è¯='{keyword}', æœ€å¤§ç»“æœ={max_results}, é¡µæ•°={max_pages}")
        
        # æ‰§è¡Œæµ‹è¯•
        start_time = time.time()
        
        results = extractor.extract_from_keyword(
            keyword=keyword,
            max_results=max_results,
            save_results=True,
            extract_details=extract_details,
            max_pages=max_pages
        )
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        # è¾“å‡ºç»“æœ
        print(f"\nâœ… æµ‹è¯•å®Œæˆ!")
        print(f"â° ç»“æŸæ—¶é—´: {time.strftime('%H:%M:%S')}")
        print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
        print(f"ğŸ“Š æå–ç»“æœ: {len(results)} ä¸ªèŒä½")
        
        if results:
            print(f"ğŸ“Š å¹³å‡æ¯ä¸ªèŒä½: {execution_time/len(results):.2f} ç§’")
            
            print(f"\nğŸ“‹ å‰3ä¸ªç»“æœ:")
            for i, job in enumerate(results[:3], 1):
                print(f"  {i}. {job.get('title', 'N/A')} - {job.get('company', 'N/A')} - {job.get('salary', 'N/A')}")
        else:
            print("âš ï¸ æ²¡æœ‰æå–åˆ°ä»»ä½•èŒä½")
        
        # æ¸…ç†
        extractor.close()
        
        return results
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return []

def test_with_details():
    """æµ‹è¯•åŒ…å«è¯¦æƒ…æå–çš„ç‰ˆæœ¬"""
    print("\n" + "="*50)
    print("ğŸ” æµ‹è¯•è¯¦æƒ…æå–åŠŸèƒ½...")
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    config = {
        'search': {
            'base_url': 'https://we.51job.com/pc/search',
            'job_area': '020000',
            'search_type': '2',
            'keyword_type': '',
            'strategy': {'max_pages': 1, 'page_delay': 1}
        },
        'selectors': {
            'search_page': {
                'job_list': '.joblist',
                'job_title': '.jname a',
                'company_name': '.cname',
                'salary': '.sal',
                'location': '.area',
                'next_page': '.btn-next'
            },
            'job_detail': {
                'job_description': '.bmsg.job_msg.inbox',
                'requirements': '.job-requirements',
                'company_info': '.company-info',
                'benefits': '.job-benefits'
            }
        },
        'selenium': {
            'headless': False,
            'window_size': '1920,1080',
            'page_load_timeout': 30,
            'element_wait_timeout': 10,
            'implicit_wait': 5
        },
        'mode': {
            'development': True,
            'debug': True,
            'skip_login': True,
            'close_on_complete': True
        },
        'database': {'enabled': True, 'path': './data/debug_jobs.db'}
    }
    
    try:
        from src.extraction.content_extractor import ContentExtractor
        
        extractor = ContentExtractor(config)
        
        # æµ‹è¯•å‚æ•° - å‡å°‘æ•°é‡ä»¥ä¾¿è§‚å¯Ÿè¯¦æƒ…æå–
        keyword = "Pythonå¼€å‘"
        max_results = 40  # åªæµ‹è¯•2ä¸ªèŒä½çš„è¯¦æƒ…
        max_pages = 2
        extract_details = True  # æå–è¯¦æƒ…
        
        print(f"ğŸ“Š è¯¦æƒ…æµ‹è¯•å‚æ•°: å…³é”®è¯='{keyword}', æœ€å¤§ç»“æœ={max_results}, æå–è¯¦æƒ…={extract_details}")
        
        start_time = time.time()
        
        results = extractor.extract_from_keyword(
            keyword=keyword,
            max_results=max_results,
            save_results=True,
            extract_details=extract_details,
            max_pages=max_pages
        )
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        print(f"\nâœ… è¯¦æƒ…æµ‹è¯•å®Œæˆ!")
        print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
        print(f"ğŸ“Š æå–ç»“æœ: {len(results)} ä¸ªèŒä½")
        
        if results:
            print(f"ğŸ“Š å¹³å‡æ¯ä¸ªèŒä½: {execution_time/len(results):.2f} ç§’")
            
            for i, job in enumerate(results, 1):
                print(f"\nğŸ“‹ èŒä½ {i}:")
                print(f"  æ ‡é¢˜: {job.get('title', 'N/A')}")
                print(f"  å…¬å¸: {job.get('company', 'N/A')}")
                print(f"  URL: {job.get('url', 'N/A')}")
                desc_len = len(job.get('description', ''))
                print(f"  æè¿°é•¿åº¦: {desc_len} å­—ç¬¦")
                if desc_len > 0:
                    print(f"  æè¿°é¢„è§ˆ: {job.get('description', '')[:100]}...")
        
        extractor.close()
        return results
        
    except Exception as e:
        print(f"âŒ è¯¦æƒ…æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return []


def test_performance_comparison():
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼ˆåŸºäºå®é™…PageParserä¼˜åŒ–ï¼‰"""
    print("\n" + "="*50)
    print("âš¡ æµ‹è¯•PageParseræ€§èƒ½ä¼˜åŒ–...")
    
    try:
        from src.extraction.page_parser import PageParser
        
        # æ¨¡æ‹Ÿé…ç½®
        config = {
            'selectors': {
                'search_page': {
                    'company_name': '.cname',
                    'salary': '.sal',
                    'location': '.area',
                    'experience': '.experience',
                    'education': '.education',
                    'job_title': '.jname a'
                }
            }
        }
        
        parser = PageParser(config)
        
        # åˆ›å»ºæ¨¡æ‹ŸèŒä½å…ƒç´ 
        class MockElement:
            def __init__(self, data):
                self.data = data
            
            def find_element(self, by, selector):
                time.sleep(0.005)  # æ¨¡æ‹ŸDOMæŸ¥è¯¢å»¶è¿Ÿ
                mock_elem = type('MockElem', (), {})()
                selector_map = {
                    '.cname': 'company',
                    '.sal': 'salary',
                    '.area': 'location',
                    '.experience': 'experience',
                    '.education': 'education',
                    '.jname a': 'title'
                }
                field = selector_map.get(selector, 'unknown')
                mock_elem.text = self.data.get(field, f"é»˜è®¤{field}")
                return mock_elem
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_jobs = []
        for i in range(10):
            job_data = {
                'title': f'Pythonå¼€å‘å·¥ç¨‹å¸ˆ{i+1}',
                'company': f'ç§‘æŠ€å…¬å¸{i+1}',
                'salary': f'{15+i*2}-{25+i*2}K',
                'location': f'å¹¿å·å¸‚{i+1}åŒº',
                'experience': f'{1+i%5}å¹´ç»éªŒ',
                'education': 'æœ¬ç§‘'
            }
            test_jobs.append(MockElement(job_data))
        
        print(f"ğŸ“Š æµ‹è¯•æ•°æ®: {len(test_jobs)} ä¸ªæ¨¡æ‹ŸèŒä½")
        
        # æµ‹è¯•åŸå§‹ä¸²è¡Œç‰ˆæœ¬ï¼ˆæ¨¡æ‹Ÿï¼‰
        print("\nğŸŒ æµ‹è¯•ä¸²è¡Œå­—æ®µæå–...")
        serial_start = time.time()
        serial_results = []
        
        for i, job_element in enumerate(test_jobs):
            # æ¨¡æ‹ŸåŸå§‹çš„ä¸²è¡Œæå–
            job_data = {'extracted_at': time.strftime('%Y-%m-%d %H:%M:%S')}
            
            # ä¸²è¡Œæå–æ¯ä¸ªå­—æ®µ
            job_data['company'] = parser._extract_text_by_selector(job_element, '.cname', 'æœªçŸ¥å…¬å¸')
            job_data['salary'] = parser._extract_text_by_selector(job_element, '.sal', 'è–ªèµ„é¢è®®')
            job_data['location'] = parser._extract_text_by_selector(job_element, '.area', 'æœªçŸ¥åœ°ç‚¹')
            job_data['experience'] = parser._extract_text_by_selector(job_element, '.experience', 'ç»éªŒä¸é™')
            job_data['education'] = parser._extract_text_by_selector(job_element, '.education', 'å­¦å†ä¸é™')
            
            serial_results.append(job_data)
        
        serial_time = time.time() - serial_start
        
        # æµ‹è¯•æ‰¹é‡ä¼˜åŒ–ç‰ˆæœ¬
        print("ğŸš€ æµ‹è¯•æ‰¹é‡å­—æ®µæå–...")
        batch_start = time.time()
        batch_results = []
        
        for job_element in test_jobs:
            # ä½¿ç”¨ä¼˜åŒ–çš„æ‰¹é‡æå–æ–¹æ³•
            job_data = {'extracted_at': time.strftime('%Y-%m-%d %H:%M:%S')}
            field_data = parser._extract_multiple_fields_batch(job_element)
            job_data.update(field_data)
            batch_results.append(job_data)
        
        batch_time = time.time() - batch_start
        
        # æ€§èƒ½å¯¹æ¯”
        print(f"\nğŸ PageParseræ€§èƒ½å¯¹æ¯”:")
        print(f"   ä¸²è¡Œæå–: {serial_time:.3f}s ({serial_time/len(test_jobs):.3f}s/èŒä½)")
        print(f"   æ‰¹é‡æå–: {batch_time:.3f}s ({batch_time/len(test_jobs):.3f}s/èŒä½)")
        
        if serial_time > batch_time:
            improvement = ((serial_time - batch_time) / serial_time) * 100
            print(f"   æ€§èƒ½æå‡: {improvement:.1f}%")
        else:
            print("   æ‰¹é‡æå–æ€§èƒ½ç›¸å½“")
        
        print(f"âœ… æµ‹è¯•å®Œæˆ: ä¸²è¡Œ={len(serial_results)}ä¸ª, æ‰¹é‡={len(batch_results)}ä¸ª")
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("ğŸ”§ ContentExtractor å¿«é€Ÿè°ƒè¯•å·¥å…·")
    print("=" * 50)
    
    # é€‰æ‹©æµ‹è¯•ç±»å‹
    print("é€‰æ‹©æµ‹è¯•ç±»å‹:")
    print("1. åŸºç¡€åŠŸèƒ½æµ‹è¯• (ä¸æå–è¯¦æƒ…)")
    print("2. è¯¦æƒ…æå–æµ‹è¯•")
    print("3. PageParseræ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    
    choice = input("è¯·è¾“å…¥ 1-3: ").strip()
    
    if choice == "1":
        results = quick_test()
    elif choice == "2":
        results = test_with_details()
    elif choice == "3":
        test_performance_comparison()
        results = []
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œæ‰§è¡ŒåŸºç¡€æµ‹è¯•...")
        results = quick_test()
    
    print(f"\nğŸ‰ è°ƒè¯•å®Œæˆ! å…±æå– {len(results)} ä¸ªèŒä½")