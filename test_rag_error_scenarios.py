#!/usr/bin/env python3
"""
RAGç³»ç»Ÿé”™è¯¯åœºæ™¯æµ‹è¯•

æµ‹è¯•RAGç³»ç»Ÿåœ¨å„ç§å¼‚å¸¸æƒ…å†µä¸‹çš„é”™è¯¯å¤„ç†èƒ½åŠ›å’Œæ¢å¤æœºåˆ¶
"""

import sys
import asyncio
import logging
import json
import sqlite3
import tempfile
import shutil
from pathlib import Path
from datetime import datetime
from unittest.mock import patch, MagicMock

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from src.rag.rag_system_coordinator import RAGSystemCoordinator
from src.rag.database_job_reader import DatabaseJobReader
from src.rag.optimized_job_processor import OptimizedJobProcessor
from src.rag.resume_optimizer import ResumeOptimizer

class ErrorScenarioTester:
    """é”™è¯¯åœºæ™¯æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_results = {
            'total_scenarios': 0,
            'passed_scenarios': 0,
            'failed_scenarios': 0,
            'scenario_details': []
        }
        
        # åŸºç¡€é…ç½®
        self.base_config = {
            'rag_system': {
                'database': {
                    'path': './data/jobs.db',
                    'batch_size': 10
                },
                'llm': {
                    'provider': 'zhipu',
                    'model': 'glm-4-flash',
                    'api_key': 'test-key',
                    'temperature': 0.1,
                    'max_tokens': 1500
                },
                'vector_db': {
                    'persist_directory': './data/test_chroma_db_error',
                    'collection_name': 'error_test_jobs',
                    'embeddings': {
                        'model_name': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                        'device': 'cpu',
                        'normalize_embeddings': True
                    }
                },
                'documents': {
                    'types': ['overview', 'responsibility', 'requirement', 'skills', 'basic_requirements']
                },
                'processing': {
                    'skip_processed': True,
                    'batch_size': 5
                }
            }
        }
    
    def log_scenario_result(self, scenario_name: str, passed: bool, details: str = "", error_handled: bool = False):
        """è®°å½•åœºæ™¯æµ‹è¯•ç»“æœ"""
        self.test_results['total_scenarios'] += 1
        if passed:
            self.test_results['passed_scenarios'] += 1
            status = "âœ… PASS"
        else:
            self.test_results['failed_scenarios'] += 1
            status = "âŒ FAIL"
        
        result = {
            'scenario_name': scenario_name,
            'status': status,
            'passed': passed,
            'error_handled': error_handled,
            'details': details,
            'timestamp': datetime.now().isoformat()
        }
        
        self.test_results['scenario_details'].append(result)
        print(f"{status} - {scenario_name}")
        if details:
            print(f"      {details}")
        if error_handled:
            print(f"      ğŸ›¡ï¸ é”™è¯¯å·²æ­£ç¡®å¤„ç†")
    
    async def test_database_connection_errors(self):
        """æµ‹è¯•æ•°æ®åº“è¿æ¥é”™è¯¯"""
        print("\nğŸ—„ï¸ é”™è¯¯åœºæ™¯1: æ•°æ®åº“è¿æ¥é”™è¯¯")
        
        # åœºæ™¯1.1: æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨
        try:
            invalid_config = self.base_config.copy()
            invalid_config['rag_system']['database']['path'] = './nonexistent/database.db'
            
            db_reader = DatabaseJobReader(invalid_config['rag_system']['database'])
            
            # å°è¯•è·å–ç»Ÿè®¡ä¿¡æ¯
            try:
                stats = db_reader.get_rag_processing_stats()
                self.log_scenario_result(
                    "æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨",
                    False,
                    "åº”è¯¥æŠ›å‡ºå¼‚å¸¸ä½†æ²¡æœ‰"
                )
            except Exception as e:
                self.log_scenario_result(
                    "æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨",
                    True,
                    f"æ­£ç¡®æŠ›å‡ºå¼‚å¸¸: {type(e).__name__}",
                    error_handled=True
                )
        except Exception as e:
            self.log_scenario_result(
                "æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨",
                True,
                f"åˆå§‹åŒ–æ—¶æ­£ç¡®æŠ›å‡ºå¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
        
        # åœºæ™¯1.2: æ•°æ®åº“æƒé™é”™è¯¯
        try:
            # åˆ›å»ºä¸€ä¸ªåªè¯»çš„ä¸´æ—¶æ•°æ®åº“æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix='.db') as temp_db:
                temp_db_path = temp_db.name
            
            # åˆ›å»ºåŸºæœ¬çš„æ•°æ®åº“ç»“æ„
            conn = sqlite3.connect(temp_db_path)
            conn.execute('''CREATE TABLE jobs (
                job_id INTEGER PRIMARY KEY,
                title TEXT,
                company TEXT,
                location TEXT
            )''')
            conn.close()
            
            # è®¾ç½®ä¸ºåªè¯»ï¼ˆåœ¨Windowsä¸Šå¯èƒ½ä¸ç”Ÿæ•ˆï¼Œä½†æµ‹è¯•é€»è¾‘ä»ç„¶æœ‰æ•ˆï¼‰
            Path(temp_db_path).chmod(0o444)
            
            readonly_config = self.base_config.copy()
            readonly_config['rag_system']['database']['path'] = temp_db_path
            
            db_reader = DatabaseJobReader(readonly_config['rag_system']['database'])
            
            try:
                # å°è¯•æ ‡è®°èŒä½ä¸ºå·²å¤„ç†ï¼ˆéœ€è¦å†™æƒé™ï¼‰
                db_reader.mark_job_as_processed(1, 5, 0.8, "test_vector_id", {})
                self.log_scenario_result(
                    "æ•°æ®åº“æƒé™é”™è¯¯",
                    False,
                    "åº”è¯¥å› æƒé™ä¸è¶³è€Œå¤±è´¥"
                )
            except Exception as e:
                self.log_scenario_result(
                    "æ•°æ®åº“æƒé™é”™è¯¯",
                    True,
                    f"æ­£ç¡®å¤„ç†æƒé™é”™è¯¯: {type(e).__name__}",
                    error_handled=True
                )
            
            # æ¸…ç†
            Path(temp_db_path).unlink(missing_ok=True)
            
        except Exception as e:
            self.log_scenario_result(
                "æ•°æ®åº“æƒé™é”™è¯¯",
                True,
                f"æµ‹è¯•è¿‡ç¨‹ä¸­æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
        
        # åœºæ™¯1.3: æ•°æ®åº“ç»“æ„ä¸åŒ¹é…
        try:
            # åˆ›å»ºç»“æ„ä¸å®Œæ•´çš„æ•°æ®åº“
            with tempfile.NamedTemporaryFile(delete=False, suffix='.db') as temp_db:
                temp_db_path = temp_db.name
            
            conn = sqlite3.connect(temp_db_path)
            conn.execute('''CREATE TABLE jobs (
                job_id INTEGER PRIMARY KEY,
                title TEXT
                -- ç¼ºå°‘å…¶ä»–å¿…è¦å­—æ®µ
            )''')
            conn.close()
            
            incomplete_config = self.base_config.copy()
            incomplete_config['rag_system']['database']['path'] = temp_db_path
            
            db_reader = DatabaseJobReader(incomplete_config['rag_system']['database'])
            
            try:
                jobs = db_reader.get_jobs_for_rag_processing(limit=1)
                # æ£€æŸ¥æ˜¯å¦èƒ½æ­£ç¡®å¤„ç†ç¼ºå¤±å­—æ®µ
                if jobs:
                    job = jobs[0]
                    missing_fields = [field for field in ['company', 'location', 'description'] 
                                    if field not in job or job[field] is None]
                    
                    self.log_scenario_result(
                        "æ•°æ®åº“ç»“æ„ä¸åŒ¹é…",
                        True,
                        f"æ­£ç¡®å¤„ç†ç¼ºå¤±å­—æ®µ: {missing_fields}",
                        error_handled=True
                    )
                else:
                    self.log_scenario_result(
                        "æ•°æ®åº“ç»“æ„ä¸åŒ¹é…",
                        True,
                        "æ²¡æœ‰æ•°æ®è¿”å›ï¼Œæ­£ç¡®å¤„ç†äº†ç»“æ„é—®é¢˜",
                        error_handled=True
                    )
            except Exception as e:
                self.log_scenario_result(
                    "æ•°æ®åº“ç»“æ„ä¸åŒ¹é…",
                    True,
                    f"æ­£ç¡®æŠ›å‡ºç»“æ„å¼‚å¸¸: {type(e).__name__}",
                    error_handled=True
                )
            
            # æ¸…ç†
            Path(temp_db_path).unlink(missing_ok=True)
            
        except Exception as e:
            self.log_scenario_result(
                "æ•°æ®åº“ç»“æ„ä¸åŒ¹é…",
                True,
                f"æµ‹è¯•è¿‡ç¨‹ä¸­æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
    
    async def test_llm_api_errors(self):
        """æµ‹è¯•LLM APIé”™è¯¯"""
        print("\nğŸ¤– é”™è¯¯åœºæ™¯2: LLM APIé”™è¯¯")
        
        # åœºæ™¯2.1: APIå¯†é’¥æ— æ•ˆ
        try:
            invalid_api_config = self.base_config.copy()
            invalid_api_config['rag_system']['llm']['api_key'] = 'invalid-api-key'
            
            processor = OptimizedJobProcessor(invalid_api_config['rag_system'])
            
            # æ¨¡æ‹ŸèŒä½æ•°æ®
            test_job = {
                'job_id': 1,
                'title': 'Pythonå¼€å‘å·¥ç¨‹å¸ˆ',
                'company': 'æµ‹è¯•å…¬å¸',
                'location': 'åŒ—äº¬',
                'description': 'è´Ÿè´£Pythonåç«¯å¼€å‘å·¥ä½œ'
            }
            
            try:
                # å°è¯•å¤„ç†èŒä½ï¼ˆä¼šè°ƒç”¨LLMï¼‰
                job_structure = await processor.process_job(test_job)
                
                # å¦‚æœæ²¡æœ‰æŠ›å‡ºå¼‚å¸¸ï¼Œæ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†å¤‡ç”¨æ–¹æ¡ˆ
                if job_structure and job_structure.job_title:
                    self.log_scenario_result(
                        "APIå¯†é’¥æ— æ•ˆ-å¤‡ç”¨æ–¹æ¡ˆ",
                        True,
                        "LLMå¤±è´¥åæ­£ç¡®ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ",
                        error_handled=True
                    )
                else:
                    self.log_scenario_result(
                        "APIå¯†é’¥æ— æ•ˆ-å¤‡ç”¨æ–¹æ¡ˆ",
                        False,
                        "å¤‡ç”¨æ–¹æ¡ˆæœªæ­£ç¡®å·¥ä½œ"
                    )
            except Exception as e:
                # æ£€æŸ¥æ˜¯å¦æœ‰é€‚å½“çš„é”™è¯¯å¤„ç†
                if "api" in str(e).lower() or "key" in str(e).lower():
                    self.log_scenario_result(
                        "APIå¯†é’¥æ— æ•ˆ-é”™è¯¯å¤„ç†",
                        True,
                        f"æ­£ç¡®è¯†åˆ«APIé”™è¯¯: {type(e).__name__}",
                        error_handled=True
                    )
                else:
                    self.log_scenario_result(
                        "APIå¯†é’¥æ— æ•ˆ-é”™è¯¯å¤„ç†",
                        False,
                        f"æœªæ­£ç¡®å¤„ç†APIé”™è¯¯: {e}"
                    )
        
        except Exception as e:
            self.log_scenario_result(
                "APIå¯†é’¥æ— æ•ˆ",
                True,
                f"åˆå§‹åŒ–æ—¶æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
        
        # åœºæ™¯2.2: ç½‘ç»œè¿æ¥è¶…æ—¶
        try:
            # ä½¿ç”¨mockæ¨¡æ‹Ÿç½‘ç»œè¶…æ—¶
            with patch('requests.post') as mock_post:
                mock_post.side_effect = Exception("Connection timeout")
                
                processor = OptimizedJobProcessor(self.base_config['rag_system'])
                
                test_job = {
                    'job_id': 1,
                    'title': 'Javaå¼€å‘å·¥ç¨‹å¸ˆ',
                    'company': 'æµ‹è¯•å…¬å¸',
                    'location': 'ä¸Šæµ·',
                    'description': 'è´Ÿè´£Javaåç«¯å¼€å‘å·¥ä½œ'
                }
                
                try:
                    job_structure = await processor.process_job(test_job)
                    
                    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†å¤‡ç”¨æ–¹æ¡ˆ
                    if job_structure and job_structure.job_title:
                        self.log_scenario_result(
                            "ç½‘ç»œè¿æ¥è¶…æ—¶",
                            True,
                            "ç½‘ç»œè¶…æ—¶åæ­£ç¡®ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ",
                            error_handled=True
                        )
                    else:
                        self.log_scenario_result(
                            "ç½‘ç»œè¿æ¥è¶…æ—¶",
                            False,
                            "ç½‘ç»œè¶…æ—¶åå¤‡ç”¨æ–¹æ¡ˆå¤±è´¥"
                        )
                except Exception as e:
                    self.log_scenario_result(
                        "ç½‘ç»œè¿æ¥è¶…æ—¶",
                        True,
                        f"æ­£ç¡®å¤„ç†ç½‘ç»œè¶…æ—¶: {type(e).__name__}",
                        error_handled=True
                    )
        
        except Exception as e:
            self.log_scenario_result(
                "ç½‘ç»œè¿æ¥è¶…æ—¶",
                True,
                f"æµ‹è¯•è¿‡ç¨‹ä¸­æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
        
        # åœºæ™¯2.3: LLMè¿”å›æ ¼å¼é”™è¯¯
        try:
            # ä½¿ç”¨mockæ¨¡æ‹Ÿé”™è¯¯çš„LLMå“åº”
            with patch('requests.post') as mock_post:
                mock_response = MagicMock()
                mock_response.json.return_value = {
                    'choices': [{'message': {'content': 'invalid json format'}}]
                }
                mock_response.status_code = 200
                mock_post.return_value = mock_response
                
                processor = OptimizedJobProcessor(self.base_config['rag_system'])
                
                test_job = {
                    'job_id': 1,
                    'title': 'Reactå¼€å‘å·¥ç¨‹å¸ˆ',
                    'company': 'æµ‹è¯•å…¬å¸',
                    'location': 'æ·±åœ³',
                    'description': 'è´Ÿè´£Reactå‰ç«¯å¼€å‘å·¥ä½œ'
                }
                
                try:
                    job_structure = await processor.process_job(test_job)
                    
                    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†å¤‡ç”¨æ–¹æ¡ˆ
                    if job_structure and job_structure.job_title:
                        self.log_scenario_result(
                            "LLMè¿”å›æ ¼å¼é”™è¯¯",
                            True,
                            "LLMæ ¼å¼é”™è¯¯åæ­£ç¡®ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ",
                            error_handled=True
                        )
                    else:
                        self.log_scenario_result(
                            "LLMè¿”å›æ ¼å¼é”™è¯¯",
                            False,
                            "LLMæ ¼å¼é”™è¯¯åå¤‡ç”¨æ–¹æ¡ˆå¤±è´¥"
                        )
                except Exception as e:
                    self.log_scenario_result(
                        "LLMè¿”å›æ ¼å¼é”™è¯¯",
                        True,
                        f"æ­£ç¡®å¤„ç†æ ¼å¼é”™è¯¯: {type(e).__name__}",
                        error_handled=True
                    )
        
        except Exception as e:
            self.log_scenario_result(
                "LLMè¿”å›æ ¼å¼é”™è¯¯",
                True,
                f"æµ‹è¯•è¿‡ç¨‹ä¸­æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
    
    async def test_vector_database_errors(self):
        """æµ‹è¯•å‘é‡æ•°æ®åº“é”™è¯¯"""
        print("\nğŸ” é”™è¯¯åœºæ™¯3: å‘é‡æ•°æ®åº“é”™è¯¯")
        
        # åœºæ™¯3.1: å‘é‡æ•°æ®åº“ç›®å½•æƒé™é”™è¯¯
        try:
            # åˆ›å»ºä¸€ä¸ªæ— æƒé™çš„ç›®å½•
            restricted_dir = Path('./restricted_chroma_test')
            restricted_dir.mkdir(exist_ok=True)
            
            try:
                # åœ¨Windowsä¸Šè®¾ç½®æƒé™å¯èƒ½ä¸ç”Ÿæ•ˆï¼Œä½†æµ‹è¯•é€»è¾‘ä»ç„¶æœ‰æ•ˆ
                restricted_dir.chmod(0o000)
                
                restricted_config = self.base_config.copy()
                restricted_config['rag_system']['vector_db']['persist_directory'] = str(restricted_dir)
                
                coordinator = RAGSystemCoordinator(restricted_config)
                
                try:
                    init_success = coordinator.initialize_system()
                    if not init_success:
                        self.log_scenario_result(
                            "å‘é‡æ•°æ®åº“æƒé™é”™è¯¯",
                            True,
                            "æ­£ç¡®æ£€æµ‹åˆ°æƒé™é—®é¢˜",
                            error_handled=True
                        )
                    else:
                        self.log_scenario_result(
                            "å‘é‡æ•°æ®åº“æƒé™é”™è¯¯",
                            False,
                            "æœªæ£€æµ‹åˆ°æƒé™é—®é¢˜"
                        )
                except Exception as e:
                    self.log_scenario_result(
                        "å‘é‡æ•°æ®åº“æƒé™é”™è¯¯",
                        True,
                        f"æ­£ç¡®å¤„ç†æƒé™å¼‚å¸¸: {type(e).__name__}",
                        error_handled=True
                    )
                
            finally:
                # æ¢å¤æƒé™å¹¶æ¸…ç†
                try:
                    restricted_dir.chmod(0o755)
                    shutil.rmtree(restricted_dir, ignore_errors=True)
                except:
                    pass
        
        except Exception as e:
            self.log_scenario_result(
                "å‘é‡æ•°æ®åº“æƒé™é”™è¯¯",
                True,
                f"æµ‹è¯•è¿‡ç¨‹ä¸­æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
        
        # åœºæ™¯3.2: å‘é‡æ•°æ®åº“ç£ç›˜ç©ºé—´ä¸è¶³ï¼ˆæ¨¡æ‹Ÿï¼‰
        try:
            coordinator = RAGSystemCoordinator(self.base_config)
            coordinator.initialize_system()
            
            # æ¨¡æ‹Ÿç£ç›˜ç©ºé—´ä¸è¶³çš„æƒ…å†µ
            with patch('chromadb.PersistentClient') as mock_client:
                mock_collection = MagicMock()
                mock_collection.add.side_effect = Exception("No space left on device")
                mock_client.return_value.get_or_create_collection.return_value = mock_collection
                
                try:
                    # å°è¯•æ·»åŠ æ–‡æ¡£
                    test_documents = [
                        {
                            'page_content': 'æµ‹è¯•æ–‡æ¡£å†…å®¹',
                            'metadata': {'job_id': 'test_001', 'doc_type': 'overview'}
                        }
                    ]
                    
                    doc_ids = coordinator.vector_manager.add_job_documents(test_documents, 'test_001')
                    
                    self.log_scenario_result(
                        "å‘é‡æ•°æ®åº“ç£ç›˜ç©ºé—´ä¸è¶³",
                        False,
                        "åº”è¯¥æŠ›å‡ºç£ç›˜ç©ºé—´å¼‚å¸¸"
                    )
                    
                except Exception as e:
                    if "space" in str(e).lower():
                        self.log_scenario_result(
                            "å‘é‡æ•°æ®åº“ç£ç›˜ç©ºé—´ä¸è¶³",
                            True,
                            f"æ­£ç¡®å¤„ç†ç£ç›˜ç©ºé—´å¼‚å¸¸: {type(e).__name__}",
                            error_handled=True
                        )
                    else:
                        self.log_scenario_result(
                            "å‘é‡æ•°æ®åº“ç£ç›˜ç©ºé—´ä¸è¶³",
                            True,
                            f"å¤„ç†äº†å¼‚å¸¸ä½†ç±»å‹ä¸åŒ¹é…: {type(e).__name__}",
                            error_handled=True
                        )
            
            coordinator.cleanup_system()
        
        except Exception as e:
            self.log_scenario_result(
                "å‘é‡æ•°æ®åº“ç£ç›˜ç©ºé—´ä¸è¶³",
                True,
                f"æµ‹è¯•è¿‡ç¨‹ä¸­æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
        
        # åœºæ™¯3.3: å‘é‡æœç´¢å¼‚å¸¸
        try:
            coordinator = RAGSystemCoordinator(self.base_config)
            coordinator.initialize_system()
            
            # æ¨¡æ‹Ÿæœç´¢å¼‚å¸¸
            with patch.object(coordinator.vector_manager.collection, 'query') as mock_query:
                mock_query.side_effect = Exception("Vector search failed")
                
                try:
                    results = coordinator.vector_manager.search_similar_jobs("æµ‹è¯•æŸ¥è¯¢", k=5)
                    
                    # æ£€æŸ¥æ˜¯å¦è¿”å›äº†ç©ºç»“æœæˆ–é»˜è®¤ç»“æœ
                    if results == [] or results is None:
                        self.log_scenario_result(
                            "å‘é‡æœç´¢å¼‚å¸¸",
                            True,
                            "æœç´¢å¼‚å¸¸åæ­£ç¡®è¿”å›ç©ºç»“æœ",
                            error_handled=True
                        )
                    else:
                        self.log_scenario_result(
                            "å‘é‡æœç´¢å¼‚å¸¸",
                            False,
                            f"æœç´¢å¼‚å¸¸åè¿”å›äº†æ„å¤–ç»“æœ: {len(results)}"
                        )
                        
                except Exception as e:
                    self.log_scenario_result(
                        "å‘é‡æœç´¢å¼‚å¸¸",
                        True,
                        f"æ­£ç¡®å¤„ç†æœç´¢å¼‚å¸¸: {type(e).__name__}",
                        error_handled=True
                    )
            
            coordinator.cleanup_system()
        
        except Exception as e:
            self.log_scenario_result(
                "å‘é‡æœç´¢å¼‚å¸¸",
                True,
                f"æµ‹è¯•è¿‡ç¨‹ä¸­æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
    
    async def test_data_validation_errors(self):
        """æµ‹è¯•æ•°æ®éªŒè¯é”™è¯¯"""
        print("\nğŸ“Š é”™è¯¯åœºæ™¯4: æ•°æ®éªŒè¯é”™è¯¯")
        
        # åœºæ™¯4.1: ç©ºæ•°æ®å¤„ç†
        try:
            processor = OptimizedJobProcessor(self.base_config['rag_system'])
            
            empty_job = {}
            
            try:
                job_structure = await processor.process_job(empty_job)
                
                if job_structure is None:
                    self.log_scenario_result(
                        "ç©ºæ•°æ®å¤„ç†",
                        True,
                        "æ­£ç¡®æ‹’ç»ç©ºæ•°æ®",
                        error_handled=True
                    )
                else:
                    self.log_scenario_result(
                        "ç©ºæ•°æ®å¤„ç†",
                        False,
                        f"ç©ºæ•°æ®è¢«é”™è¯¯å¤„ç†: {job_structure}"
                    )
            except Exception as e:
                self.log_scenario_result(
                    "ç©ºæ•°æ®å¤„ç†",
                    True,
                    f"æ­£ç¡®æŠ›å‡ºç©ºæ•°æ®å¼‚å¸¸: {type(e).__name__}",
                    error_handled=True
                )
        
        except Exception as e:
            self.log_scenario_result(
                "ç©ºæ•°æ®å¤„ç†",
                True,
                f"æµ‹è¯•è¿‡ç¨‹ä¸­æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
        
        # åœºæ™¯4.2: æ¶æ„æ•°æ®å¤„ç†
        try:
            processor = OptimizedJobProcessor(self.base_config['rag_system'])
            
            malicious_job = {
                'job_id': 1,
                'title': '<script>alert("xss")</script>',
                'company': '"; DROP TABLE jobs; --',
                'location': '\x00\x01\x02æ¶æ„å­—ç¬¦',
                'description': 'A' * 10000  # è¶…é•¿æè¿°
            }
            
            try:
                job_structure = await processor.process_job(malicious_job)
                
                # æ£€æŸ¥æ˜¯å¦æ­£ç¡®æ¸…ç†äº†æ¶æ„å†…å®¹
                if job_structure:
                    title_safe = '<script>' not in job_structure.job_title
                    company_safe = 'DROP TABLE' not in job_structure.company
                    
                    if title_safe and company_safe:
                        self.log_scenario_result(
                            "æ¶æ„æ•°æ®å¤„ç†",
                            True,
                            "æ­£ç¡®æ¸…ç†äº†æ¶æ„å†…å®¹",
                            error_handled=True
                        )
                    else:
                        self.log_scenario_result(
                            "æ¶æ„æ•°æ®å¤„ç†",
                            False,
                            "æœªæ­£ç¡®æ¸…ç†æ¶æ„å†…å®¹"
                        )
                else:
                    self.log_scenario_result(
                        "æ¶æ„æ•°æ®å¤„ç†",
                        True,
                        "æ­£ç¡®æ‹’ç»æ¶æ„æ•°æ®",
                        error_handled=True
                    )
            except Exception as e:
                self.log_scenario_result(
                    "æ¶æ„æ•°æ®å¤„ç†",
                    True,
                    f"æ­£ç¡®å¤„ç†æ¶æ„æ•°æ®å¼‚å¸¸: {type(e).__name__}",
                    error_handled=True
                )
        
        except Exception as e:
            self.log_scenario_result(
                "æ¶æ„æ•°æ®å¤„ç†",
                True,
                f"æµ‹è¯•è¿‡ç¨‹ä¸­æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
        
        # åœºæ™¯4.3: ç¼–ç é”™è¯¯å¤„ç†
        try:
            processor = OptimizedJobProcessor(self.base_config['rag_system'])
            
            encoding_job = {
                'job_id': 1,
                'title': 'è½¯ä»¶å·¥ç¨‹å¸ˆ',  # ä¸­æ–‡
                'company': 'SociÃ©tÃ© GÃ©nÃ©rale',  # æ³•æ–‡
                'location': 'ĞœĞ¾ÑĞºĞ²Ğ°',  # ä¿„æ–‡
                'description': 'ğŸš€ Exciting opportunity! ğŸ’»'  # è¡¨æƒ…ç¬¦å·
            }
            
            try:
                job_structure = await processor.process_job(encoding_job)
                
                if job_structure and job_structure.job_title:
                    self.log_scenario_result(
                        "ç¼–ç é”™è¯¯å¤„ç†",
                        True,
                        "æ­£ç¡®å¤„ç†å¤šè¯­è¨€å’Œç‰¹æ®Šå­—ç¬¦",
                        error_handled=True
                    )
                else:
                    self.log_scenario_result(
                        "ç¼–ç é”™è¯¯å¤„ç†",
                        False,
                        "æœªæ­£ç¡®å¤„ç†ç¼–ç é—®é¢˜"
                    )
            except Exception as e:
                if "encoding" in str(e).lower() or "decode" in str(e).lower():
                    self.log_scenario_result(
                        "ç¼–ç é”™è¯¯å¤„ç†",
                        True,
                        f"æ­£ç¡®è¯†åˆ«ç¼–ç å¼‚å¸¸: {type(e).__name__}",
                        error_handled=True
                    )
                else:
                    self.log_scenario_result(
                        "ç¼–ç é”™è¯¯å¤„ç†",
                        False,
                        f"ç¼–ç å¤„ç†å¼‚å¸¸: {e}"
                    )
        
        except Exception as e:
            self.log_scenario_result(
                "ç¼–ç é”™è¯¯å¤„ç†",
                True,
                f"æµ‹è¯•è¿‡ç¨‹ä¸­æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
    
    async def test_resource_exhaustion(self):
        """æµ‹è¯•èµ„æºè€—å°½åœºæ™¯"""
        print("\nğŸ’¾ é”™è¯¯åœºæ™¯5: èµ„æºè€—å°½")
        
        # åœºæ™¯5.1: å†…å­˜ä¸è¶³ï¼ˆæ¨¡æ‹Ÿï¼‰
        try:
            coordinator = RAGSystemCoordinator(self.base_config)
            coordinator.initialize_system()
            
            # æ¨¡æ‹Ÿå†…å­˜ä¸è¶³
            with patch('chromadb.PersistentClient') as mock_client:
                mock_collection = MagicMock()
                mock_collection.add.side_effect = MemoryError("Out of memory")
                mock_client.return_value.get_or_create_collection.return_value = mock_collection
                
                try:
                    test_documents = [
                        {
                            'page_content': 'æµ‹è¯•æ–‡æ¡£å†…å®¹',
                            'metadata': {'job_id': 'test_001', 'doc_type': 'overview'}
                        }
                    ]
                    
                    doc_ids = coordinator.vector_manager.add_job_documents(test_documents, 'test_001')
                    
                    self.log_scenario_result(
                        "å†…å­˜ä¸è¶³å¤„ç†",
                        False,
                        "åº”è¯¥æŠ›å‡ºå†…å­˜ä¸è¶³å¼‚å¸¸"
                    )
                    
                except MemoryError as e:
                    self.log_scenario_result(
                        "å†…å­˜ä¸è¶³å¤„ç†",
                        True,
                        f"æ­£ç¡®å¤„ç†å†…å­˜ä¸è¶³: {type(e).__name__}",
                        error_handled=True
                    )
                except Exception as e:
                    self.log_scenario_result(
                        "å†…å­˜ä¸è¶³å¤„ç†",
                        True,
                        f"å¤„ç†äº†å¼‚å¸¸: {type(e).__name__}",
                        error_handled=True
                    )
            
            coordinator.cleanup_system()
        
        except Exception as e:
            self.log_scenario_result(
                "å†…å­˜ä¸è¶³å¤„ç†",
                True,
                f"æµ‹è¯•è¿‡ç¨‹ä¸­æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
        
        # åœºæ™¯5.2: æ–‡ä»¶å¥æŸ„è€—å°½ï¼ˆæ¨¡æ‹Ÿï¼‰
        try:
            # æ¨¡æ‹Ÿæ–‡ä»¶å¥æŸ„è€—å°½
            with patch('sqlite3.connect') as mock_connect:
                mock_connect.side_effect = OSError("Too many open files")
                
                try:
                    db_reader = DatabaseJobReader(self.base_config['rag_system']['database'])
                    stats = db_reader.get_rag_processing_stats()
                    
                    self.log_scenario_result(
                        "æ–‡ä»¶å¥æŸ„è€—å°½",
                        False,
                        "åº”è¯¥æŠ›å‡ºæ–‡ä»¶å¥æŸ„å¼‚å¸¸"
                    )
                    
                except OSError as e:
                    if "files" in str(e).lower():
                        self.log_scenario_result(
                            "æ–‡ä»¶å¥æŸ„è€—å°½",
                            True,
                            f"æ­£ç¡®å¤„ç†æ–‡ä»¶å¥æŸ„å¼‚å¸¸: {type(e).__name__}",
                            error_handled=True
                        )
                    else:
                        self.log_scenario_result(
                            "æ–‡ä»¶å¥æŸ„è€—å°½",
                            True,
                            f"å¤„ç†äº†OSå¼‚å¸¸: {type(e).__name__}",
                            error_handled=True
                        )
                except Exception as e:
                    self.log_scenario_result(
                        "æ–‡ä»¶å¥æŸ„è€—å°½",
                        True,
                        f"å¤„ç†äº†å¼‚å¸¸: {type(e).__name__}",
                        error_handled=True
                    )
        
        except Exception as e:
            self.log_scenario_result(
                "æ–‡ä»¶å¥æŸ„è€—å°½",
                True,
                f"æµ‹è¯•è¿‡ç¨‹ä¸­æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}",
                error_handled=True
            )
    
    def generate_error_scenario_report(self):
        """ç”Ÿæˆé”™è¯¯åœºæ™¯æµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ›¡ï¸ RAGç³»ç»Ÿé”™è¯¯åœºæ™¯æµ‹è¯•æŠ¥å‘Š")
        print("="*60)
        
        # æ€»ä½“ç»Ÿè®¡
        total = self.test_results['total_scenarios']
        passed = self.test_results['passed_scenarios']
        failed = self.test_results['failed_scenarios']
        success_rate = (passed / total * 100) if total > 0 else 0
        
        print(f"æ€»åœºæ™¯æ•°: {total}")
        print(f"é€šè¿‡æ•°: {passed}")
        print(f"å¤±è´¥æ•°: {failed}")
        print(f"æˆåŠŸç‡: {success_rate:.1f}%")
        
        # é”™è¯¯å¤„ç†ç»Ÿè®¡
        error_handled_count = sum(1 for result in self.test_results['scenario_details']
                                if result.get('error_handled', False))
        
        print(f"é”™è¯¯æ­£ç¡®å¤„ç†æ•°: {error_handled_count}")
        print(f"é”™è¯¯å¤„ç†ç‡: {(error_handled_count / total * 100):.1f}%")
        
        # è¯¦ç»†ç»“æœ
        print(f"\nğŸ“ è¯¦ç»†åœºæ™¯ç»“æœ:")
        for result in self.test_results['scenario_details']:
            status_icon = "ğŸ›¡ï¸" if result.get('error_handled', False) else ""
            print(f"  {result['status']} {result['scenario_name']} {status_icon}")
            if result['details']:
                print(f"      {result['details']}")
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f"./test_reports/rag_error_scenarios_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        Path(report_file).parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ’¾ é”™è¯¯åœºæ™¯æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        return success_rate >= 70 and error_handled_count >= total * 0.8  # 70%é€šè¿‡ç‡ä¸”80%é”™è¯¯æ­£ç¡®å¤„ç†
    
    async def run_all_error_scenarios(self):
        """è¿è¡Œæ‰€æœ‰é”™è¯¯åœºæ™¯æµ‹è¯•"""
        print("ğŸ§ª å¼€å§‹RAGç³»ç»Ÿé”™è¯¯åœºæ™¯æµ‹è¯•")
        print("="*60)
        
        try:
            await self.test_database_connection_errors()
            await self.test_llm_api_errors()
            await self.test_vector_database_errors()
            await self.test_data_validation_errors()
            await self.test_resource_exhaustion()
            
            success = self.generate_error_scenario_report()
            
            return success
            
        except Exception as e:
            print(f"âŒ é”™è¯¯åœºæ™¯æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return False

async def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.ERROR,  # åªæ˜¾ç¤ºé”™è¯¯æ—¥å¿—
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºé”™è¯¯åœºæ™¯æµ‹è¯•å™¨å¹¶è¿è¡Œ
    tester = ErrorScenarioTester()
    success = await tester.run_all_error_scenarios()
    
    return success

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)