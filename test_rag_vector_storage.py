#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•RAGå‘é‡å­˜å‚¨åŠŸèƒ½

éªŒè¯JSONèŒä½æ•°æ®ä¿å­˜åˆ°å‘é‡æ•°æ®åº“çš„å®Œæ•´æµç¨‹
"""

import os
import sys
import json
import logging
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.rag.vector_manager import ChromaDBManager
from src.rag.job_processor import LangChainJobProcessor
from src.rag.document_creator import DocumentCreator
from src.rag.rag_chain import JobRAGSystem
from src.rag.semantic_search import SemanticSearchEngine

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æ™ºè°±GLM APIå¯†é’¥
API_KEY = "0175134f27a040709d7541e14b4db353.V3KP9u8rZ0oQj9s9"

class RAGVectorStorageTest:
    """RAGå‘é‡å­˜å‚¨æµ‹è¯•ç±»"""
    
    def __init__(self, api_key: str):
        """
        åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ
        
        Args:
            api_key: æ™ºè°±GLM APIå¯†é’¥
        """
        self.api_key = api_key
        
        # RAGç³»ç»Ÿé…ç½®
        self.config = {
            'vectorstore': {
                'persist_directory': './test_chroma_db',
                'collection_name': 'test_job_positions'
            },
            'embeddings': {
                'model_name': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                'device': 'cpu',
                'normalize_embeddings': True
            },
            'llm': {
                'provider': 'zhipu',
                'api_key': api_key,
                'model': 'glm-4-flash',
                'temperature': 0.1,
                'max_tokens': 2000
            },
            'text_splitter': {
                'chunk_size': 500,
                'chunk_overlap': 50
            }
        }
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.vector_manager = None
        self.job_processor = None
        self.document_creator = None
        self.rag_system = None
        self.search_engine = None
    
    def setup_components(self):
        """è®¾ç½®RAGç»„ä»¶"""
        try:
            logger.info("ğŸ”§ åˆå§‹åŒ–RAGç»„ä»¶...")
            
            # 1. åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨
            self.vector_manager = ChromaDBManager(self.config['vectorstore'])
            logger.info("âœ… å‘é‡å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
            # 2. åˆå§‹åŒ–èŒä½å¤„ç†å™¨
            self.job_processor = LangChainJobProcessor(
                llm_config=self.config['llm'],
                config=self.config['text_splitter']
            )
            logger.info("âœ… èŒä½å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
            # 3. åˆå§‹åŒ–æ–‡æ¡£åˆ›å»ºå™¨
            self.document_creator = DocumentCreator(self.config)
            logger.info("âœ… æ–‡æ¡£åˆ›å»ºå™¨åˆå§‹åŒ–å®Œæˆ")
            
            # 4. åˆå§‹åŒ–RAGç³»ç»Ÿ
            self.rag_system = JobRAGSystem(
                vectorstore_manager=self.vector_manager,
                config=self.config
            )
            logger.info("âœ… RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
            # 5. åˆå§‹åŒ–è¯­ä¹‰æœç´¢å¼•æ“
            self.search_engine = SemanticSearchEngine(
                vector_manager=self.vector_manager,
                config=self.config
            )
            logger.info("âœ… è¯­ä¹‰æœç´¢å¼•æ“åˆå§‹åŒ–å®Œæˆ")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def load_job_data(self, json_file: str) -> dict:
        """åŠ è½½èŒä½JSONæ•°æ®"""
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            logger.info(f"ğŸ“‚ æˆåŠŸåŠ è½½èŒä½æ•°æ®: {json_file}")
            return data
        except Exception as e:
            logger.error(f"âŒ åŠ è½½èŒä½æ•°æ®å¤±è´¥: {e}")
            return {}
    
    async def test_job_processing(self, job_data: dict) -> bool:
        """æµ‹è¯•èŒä½æ•°æ®å¤„ç†"""
        try:
            logger.info("ğŸ” å¼€å§‹èŒä½æ•°æ®å¤„ç†...")
            
            # 1. ç»“æ„åŒ–æå–èŒä½ä¿¡æ¯
            job_structure = await self.job_processor.process_job_data(job_data)
            logger.info(f"âœ… èŒä½ç»“æ„åŒ–æå–å®Œæˆ: {job_structure.job_title}")
            
            # 2. åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            documents = self.document_creator.create_job_documents(
                job_structure=job_structure,
                job_id="test_job_001",
                source_url=job_data.get('url', '')
            )
            logger.info(f"âœ… åˆ›å»ºäº† {len(documents)} ä¸ªæ–‡æ¡£å¯¹è±¡")
            
            # 3. ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
            doc_ids = self.vector_manager.add_job_documents(
                documents=documents,
                job_id="test_job_001"
            )
            logger.info(f"âœ… æˆåŠŸä¿å­˜ {len(doc_ids)} ä¸ªæ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“")
            
            # 4. éªŒè¯å­˜å‚¨
            stats = self.vector_manager.get_collection_stats()
            logger.info(f"ğŸ“Š å‘é‡æ•°æ®åº“ç»Ÿè®¡: {stats}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ èŒä½æ•°æ®å¤„ç†å¤±è´¥: {e}")
            return False
    
    def test_vector_search(self) -> bool:
        """æµ‹è¯•å‘é‡æœç´¢åŠŸèƒ½"""
        try:
            logger.info("ğŸ” å¼€å§‹å‘é‡æœç´¢æµ‹è¯•...")
            
            # æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
            test_queries = [
                "AIå·¥ç¨‹å¸ˆèŒä½è¦æ±‚",
                "Pythonå¼€å‘ç»éªŒ",
                "æœºå™¨å­¦ä¹ æŠ€èƒ½",
                "LLMåº”ç”¨å¼€å‘",
                "è–ªèµ„å¾…é‡"
            ]
            
            for query in test_queries:
                logger.info(f"ğŸ” æœç´¢æŸ¥è¯¢: {query}")
                
                # 1. ç›¸ä¼¼åº¦æœç´¢
                results = self.search_engine.search(
                    query=query,
                    strategy='similarity',
                    k=3
                )
                
                logger.info(f"  ğŸ“‹ æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ")
                
                for i, result in enumerate(results, 1):
                    logger.info(f"    {i}. ç›¸ä¼¼åº¦: {result['similarity_score']:.3f}")
                    logger.info(f"       å†…å®¹: {result['content'][:100]}...")
                    logger.info(f"       ç±»å‹: {result['metadata'].get('type', 'unknown')}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å‘é‡æœç´¢æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_rag_qa(self) -> bool:
        """æµ‹è¯•RAGé—®ç­”åŠŸèƒ½"""
        try:
            logger.info("ğŸ’¬ å¼€å§‹RAGé—®ç­”æµ‹è¯•...")
            
            # æµ‹è¯•é—®é¢˜åˆ—è¡¨
            test_questions = [
                "è¿™ä¸ªèŒä½éœ€è¦ä»€ä¹ˆæŠ€èƒ½ï¼Ÿ",
                "å·¥ä½œç»éªŒè¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ",
                "è–ªèµ„èŒƒå›´æ˜¯å¤šå°‘ï¼Ÿ",
                "ä¸»è¦å·¥ä½œèŒè´£æœ‰å“ªäº›ï¼Ÿ",
                "å­¦å†è¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ"
            ]
            
            for question in test_questions:
                logger.info(f"â“ é—®é¢˜: {question}")
                
                # ä½¿ç”¨RAGç³»ç»Ÿå›ç­”é—®é¢˜
                answer_result = await self.rag_system.ask_question(
                    question=question,
                    k=5
                )
                
                logger.info(f"  ğŸ’¡ å›ç­”: {answer_result['answer'][:200]}...")
                logger.info(f"  ğŸ“Š ç½®ä¿¡åº¦: {answer_result['confidence']:.3f}")
                logger.info(f"  ğŸ“š å‚è€ƒæ–‡æ¡£æ•°: {len(answer_result['source_documents'])}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ RAGé—®ç­”æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def cleanup(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        try:
            # å…ˆå…³é—­æ‰€æœ‰ç»„ä»¶è¿æ¥
            if self.vector_manager:
                self.vector_manager.close()
            
            # æ¸…ç†ç»„ä»¶å¼•ç”¨
            self.vector_manager = None
            self.job_processor = None
            self.document_creator = None
            self.rag_system = None
            self.search_engine = None
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            import gc
            gc.collect()
            
            # ç­‰å¾…ä¸€ä¸‹è®©æ–‡ä»¶å¥æŸ„é‡Šæ”¾
            import time
            time.sleep(1)
            
            # åˆ é™¤æµ‹è¯•æ•°æ®åº“
            import shutil
            test_db_path = self.config['vectorstore']['persist_directory']
            if os.path.exists(test_db_path):
                try:
                    shutil.rmtree(test_db_path)
                    logger.info("ğŸ§¹ æ¸…ç†æµ‹è¯•æ•°æ®åº“å®Œæˆ")
                except PermissionError as pe:
                    # Windowsæ–‡ä»¶è®¿é—®æƒé™é—®é¢˜ï¼Œè¿™æ˜¯æ­£å¸¸çš„
                    logger.info("ğŸ§¹ æµ‹è¯•å®Œæˆï¼Œæ•°æ®åº“æ–‡ä»¶å°†åœ¨è¿›ç¨‹ç»“æŸåè‡ªåŠ¨æ¸…ç†")
                
        except Exception as e:
            logger.warning(f"âš ï¸ æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°è­¦å‘Š: {e}")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ RAGå‘é‡å­˜å‚¨åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥APIå¯†é’¥
    if not API_KEY or API_KEY == "your_api_key_here":
        print("âŒ è¯·å…ˆè®¾ç½®æ™ºè°±GLM APIå¯†é’¥")
        return
    
    # æ£€æŸ¥JSONæ–‡ä»¶
    json_file = "fixed_job_detail_result.json"
    if not os.path.exists(json_file):
        print(f"âŒ æ‰¾ä¸åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶: {json_file}")
        return
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    test = RAGVectorStorageTest(API_KEY)
    
    try:
        # 1. è®¾ç½®ç»„ä»¶
        print("\nğŸ“‹ æ­¥éª¤1: åˆå§‹åŒ–RAGç»„ä»¶")
        if not test.setup_components():
            print("âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥")
            return
        
        # 2. åŠ è½½æµ‹è¯•æ•°æ®
        print("\nğŸ“‹ æ­¥éª¤2: åŠ è½½èŒä½æ•°æ®")
        job_data = test.load_job_data(json_file)
        if not job_data:
            print("âŒ èŒä½æ•°æ®åŠ è½½å¤±è´¥")
            return
        
        # 3. æµ‹è¯•èŒä½æ•°æ®å¤„ç†å’Œå­˜å‚¨
        print("\nğŸ“‹ æ­¥éª¤3: æµ‹è¯•èŒä½æ•°æ®å¤„ç†å’Œå‘é‡å­˜å‚¨")
        if not await test.test_job_processing(job_data):
            print("âŒ èŒä½æ•°æ®å¤„ç†å¤±è´¥")
            return
        
        # 4. æµ‹è¯•å‘é‡æœç´¢
        print("\nğŸ“‹ æ­¥éª¤4: æµ‹è¯•å‘é‡æœç´¢åŠŸèƒ½")
        if not test.test_vector_search():
            print("âŒ å‘é‡æœç´¢æµ‹è¯•å¤±è´¥")
            return
        
        # 5. æµ‹è¯•RAGé—®ç­”
        print("\nğŸ“‹ æ­¥éª¤5: æµ‹è¯•RAGé—®ç­”åŠŸèƒ½")
        if not await test.test_rag_qa():
            print("âŒ RAGé—®ç­”æµ‹è¯•å¤±è´¥")
            return
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼RAGå‘é‡å­˜å‚¨åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        print("\nâœ… æµ‹è¯•ç»“æœæ€»ç»“:")
        print("  - æ™ºè°±GLMé›†æˆæˆåŠŸ")
        print("  - èŒä½æ•°æ®ç»“æ„åŒ–æå–æ­£å¸¸")
        print("  - å‘é‡æ•°æ®åº“å­˜å‚¨æˆåŠŸ")
        print("  - è¯­ä¹‰æœç´¢åŠŸèƒ½æ­£å¸¸")
        print("  - RAGé—®ç­”ç³»ç»Ÿå·¥ä½œæ­£å¸¸")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # æ¸…ç†æµ‹è¯•ç¯å¢ƒ
        print("\nğŸ§¹ æ¸…ç†æµ‹è¯•ç¯å¢ƒ...")
        test.cleanup()

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())