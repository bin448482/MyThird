#!/usr/bin/env python3
"""
æµ‹è¯•ResumeOptimizeråŠŸèƒ½
"""

import sys
import asyncio
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from src.rag.resume_optimizer import ResumeOptimizer
from src.rag.rag_system_coordinator import RAGSystemCoordinator

def test_resume_optimizer():
    """æµ‹è¯•ç®€å†ä¼˜åŒ–å™¨"""
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("ğŸ§ª æµ‹è¯•ResumeOptimizeråŠŸèƒ½")
    print("=" * 50)
    
    async def run_tests():
        try:
            # é…ç½®ç³»ç»Ÿ
            config = {
                'rag_system': {
                    'database': {
                        'path': './data/jobs.db',
                        'batch_size': 10
                    },
                    'llm': {
                        'provider': 'zhipu',
                        'model': 'glm-4-flash',
                        'api_key': 'test-key',  # æµ‹è¯•ç”¨
                        'temperature': 0.3,
                        'max_tokens': 2000
                    },
                    'vector_db': {
                        'persist_directory': './test_chroma_db',
                        'collection_name': 'test_job_positions',
                        'embeddings': {
                            'model_name': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                            'device': 'cpu',
                            'normalize_embeddings': True
                        }
                    },
                    'documents': {
                        'types': ['overview', 'responsibility', 'requirement', 'skills', 'basic_requirements']
                    }
                }
            }
            
            # åˆå§‹åŒ–ç»„ä»¶
            coordinator = RAGSystemCoordinator(config)
            coordinator.initialize_system()
            
            llm_config = config['rag_system']['llm']
            optimizer = ResumeOptimizer(coordinator, llm_config)
            print("âœ… ResumeOptimizeråˆå§‹åŒ–æˆåŠŸ")
            
            # æµ‹è¯•ç®€å†æ•°æ®
            test_resume = {
                'name': 'å¼ ä¸‰',
                'current_position': 'Pythonå¼€å‘å·¥ç¨‹å¸ˆ',
                'years_of_experience': 3,
                'education': 'æœ¬ç§‘ - è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯',
                'skills': ['Python', 'Django', 'MySQL', 'Git', 'Linux'],
                'summary': 'å…·æœ‰3å¹´Pythonå¼€å‘ç»éªŒï¼Œç†Ÿæ‚‰Webå¼€å‘å’Œæ•°æ®åº“è®¾è®¡ï¼Œæœ‰è‰¯å¥½çš„ç¼–ç¨‹ä¹ æƒ¯å’Œå›¢é˜Ÿåä½œèƒ½åŠ›ã€‚',
                'experience': [
                    {
                        'position': 'Pythonå¼€å‘å·¥ç¨‹å¸ˆ',
                        'company': 'ABCç§‘æŠ€æœ‰é™å…¬å¸',
                        'duration': '2021-2024',
                        'description': 'è´Ÿè´£Webåº”ç”¨å¼€å‘ï¼Œå‚ä¸ç³»ç»Ÿæ¶æ„è®¾è®¡ï¼Œç»´æŠ¤æ•°æ®åº“'
                    },
                    {
                        'position': 'è½¯ä»¶å¼€å‘å®ä¹ ç”Ÿ',
                        'company': 'XYZè½¯ä»¶å…¬å¸',
                        'duration': '2020-2021',
                        'description': 'å‚ä¸é¡¹ç›®å¼€å‘ï¼Œå­¦ä¹ ç¼–ç¨‹è§„èŒƒï¼ŒååŠ©æµ‹è¯•å·¥ä½œ'
                    }
                ]
            }
            
            # è·å–æµ‹è¯•èŒä½
            test_jobs = coordinator.db_reader.get_jobs_for_rag_processing(limit=2)
            if not test_jobs:
                print("âš ï¸ æ²¡æœ‰å¯æµ‹è¯•çš„èŒä½æ•°æ®")
                return False
            
            test_job_ids = [job['job_id'] for job in test_jobs]
            
            # æµ‹è¯•1: ç®€å†å·®è·åˆ†æï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
            print("\nğŸ” æµ‹è¯•1: ç®€å†å·®è·åˆ†æï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰")
            print(f"   åˆ†æèŒä½æ•°: {len(test_job_ids)}")
            for i, job in enumerate(test_jobs, 1):
                print(f"   èŒä½{i}: {job.get('title', 'æ— æ ‡é¢˜')} - {job.get('company', 'æ— å…¬å¸')}")
            
            print("   âš ï¸ è·³è¿‡å®é™…LLMè°ƒç”¨ï¼ˆé¿å…APIè´¹ç”¨ï¼‰")
            
            # æ¨¡æ‹Ÿå·®è·åˆ†æç»“æœ
            mock_gap_analysis = {
                'individual_analyses': [
                    {
                        'job_id': test_job_ids[0],
                        'job_title': test_jobs[0].get('title', ''),
                        'company': test_jobs[0].get('company', ''),
                        'overall_match_score': 0.75,
                        'skill_gaps': [
                            {'missing_skill': 'React', 'importance': 'é«˜', 'suggestion': 'å­¦ä¹ å‰ç«¯æ¡†æ¶'},
                            {'missing_skill': 'Docker', 'importance': 'ä¸­', 'suggestion': 'å­¦ä¹ å®¹å™¨åŒ–æŠ€æœ¯'}
                        ],
                        'priority_improvements': ['å­¦ä¹ React', 'æŒæ¡Docker', 'æå‡é¡¹ç›®ç»éªŒ']
                    }
                ],
                'summary': {
                    'average_match_score': 0.75,
                    'most_common_skill_gaps': [('React', 1), ('Docker', 1)],
                    'total_jobs_analyzed': 1
                }
            }
            
            print(f"   æ¨¡æ‹Ÿåˆ†æç»“æœ:")
            print(f"      å¹³å‡åŒ¹é…åº¦: {mock_gap_analysis['summary']['average_match_score']}")
            print(f"      å¸¸è§æŠ€èƒ½å·®è·: {mock_gap_analysis['summary']['most_common_skill_gaps']}")
            
            # æµ‹è¯•2: æŠ€èƒ½æå‡å»ºè®®ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
            print("\nğŸ’¡ æµ‹è¯•2: æŠ€èƒ½æå‡å»ºè®®ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰")
            print("   âš ï¸ è·³è¿‡å®é™…LLMè°ƒç”¨")
            
            # æ¨¡æ‹ŸæŠ€èƒ½å»ºè®®
            mock_skill_suggestions = {
                'immediate_skills': [
                    {
                        'skill': 'React',
                        'priority': 'é«˜',
                        'learning_path': 'å®˜æ–¹æ–‡æ¡£ -> å®è·µé¡¹ç›® -> è¿›é˜¶åº”ç”¨',
                        'estimated_time': '2-3ä¸ªæœˆ'
                    }
                ],
                'long_term_skills': [
                    {
                        'skill': 'å¾®æœåŠ¡æ¶æ„',
                        'market_demand': 'é«˜',
                        'career_impact': 'æ˜¾è‘—æå‡æ¶æ„èƒ½åŠ›'
                    }
                ]
            }
            
            print(f"   å³æ—¶æŠ€èƒ½å»ºè®®: {len(mock_skill_suggestions['immediate_skills'])} ä¸ª")
            print(f"   é•¿æœŸæŠ€èƒ½å»ºè®®: {len(mock_skill_suggestions['long_term_skills'])} ä¸ª")
            
            # æµ‹è¯•3: ç®€å†å†…å®¹ä¼˜åŒ–ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
            print("\nğŸ“ æµ‹è¯•3: ç®€å†å†…å®¹ä¼˜åŒ–ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰")
            target_job_id = test_job_ids[0]
            print(f"   ç›®æ ‡èŒä½: {target_job_id}")
            print("   âš ï¸ è·³è¿‡å®é™…LLMè°ƒç”¨")
            
            # æ¨¡æ‹Ÿä¼˜åŒ–å»ºè®®
            mock_optimization = {
                'summary_optimization': {
                    'original': test_resume['summary'],
                    'optimized': 'å…·æœ‰3å¹´Pythonå¼€å‘ç»éªŒï¼Œç²¾é€šDjangoæ¡†æ¶å’ŒMySQLæ•°æ®åº“ï¼Œç†Ÿæ‚‰å‰åç«¯å¼€å‘æµç¨‹...',
                    'improvements': ['çªå‡ºæŠ€æœ¯æ ˆ', 'é‡åŒ–å·¥ä½œæˆæœ']
                },
                'keyword_optimization': {
                    'missing_keywords': ['APIå¼€å‘', 'æ•æ·å¼€å‘'],
                    'ats_optimization': ['å¢åŠ è¡Œä¸šå…³é”®è¯', 'ä¼˜åŒ–æŠ€èƒ½æè¿°']
                }
            }
            
            print(f"   ä¼˜åŒ–å»ºè®®ç±»å‹: ä¸ªäººç®€ä»‹ä¼˜åŒ–ã€å…³é”®è¯ä¼˜åŒ–")
            print(f"   ç¼ºå¤±å…³é”®è¯: {mock_optimization['keyword_optimization']['missing_keywords']}")
            
            # æµ‹è¯•4: æ±‚èŒä¿¡ç”Ÿæˆï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
            print("\nâœ‰ï¸ æµ‹è¯•4: æ±‚èŒä¿¡ç”Ÿæˆï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰")
            print(f"   ç›®æ ‡èŒä½: {test_jobs[0].get('title', '')} - {test_jobs[0].get('company', '')}")
            print("   âš ï¸ è·³è¿‡å®é™…LLMè°ƒç”¨")
            
            # æ¨¡æ‹Ÿæ±‚èŒä¿¡
            mock_cover_letter = f"""
å°Šæ•¬çš„{test_jobs[0].get('company', '')}æ‹›è˜è´Ÿè´£äººï¼š

æ‚¨å¥½ï¼æˆ‘æ˜¯{test_resume['name']}ï¼Œä¸€åå…·æœ‰{test_resume['years_of_experience']}å¹´ç»éªŒçš„{test_resume['current_position']}ã€‚
æˆ‘å¯¹è´µå…¬å¸çš„{test_jobs[0].get('title', '')}èŒä½éå¸¸æ„Ÿå…´è¶£...

ï¼ˆæ¨¡æ‹Ÿç”Ÿæˆçš„æ±‚èŒä¿¡å†…å®¹ï¼‰

æ­¤è‡´
æ•¬ç¤¼ï¼

{test_resume['name']}
"""
            
            print(f"   æ±‚èŒä¿¡é•¿åº¦: {len(mock_cover_letter)} å­—ç¬¦")
            print(f"   åŒ…å«è¦ç´ : ä¸ªäººä»‹ç»ã€èŒä½å…´è¶£ã€æŠ€èƒ½åŒ¹é…")
            
            # æµ‹è¯•5: æ•°æ®æ ¼å¼åŒ–åŠŸèƒ½
            print("\nğŸ”§ æµ‹è¯•5: æ•°æ®æ ¼å¼åŒ–åŠŸèƒ½")
            
            # æµ‹è¯•ç®€å†ä¿¡æ¯æ ¼å¼åŒ–
            formatted_resume = optimizer._format_resume_info(test_resume)
            print(f"   ç®€å†ä¿¡æ¯æ ¼å¼åŒ–: {len(formatted_resume)} å­—ç¬¦")
            
            # æµ‹è¯•èŒä½ä¿¡æ¯æ ¼å¼åŒ–
            formatted_job = optimizer._format_job_info(test_jobs[0])
            print(f"   èŒä½ä¿¡æ¯æ ¼å¼åŒ–: {len(formatted_job)} å­—ç¬¦")
            
            # æµ‹è¯•JSONè§£æåŠŸèƒ½
            test_json = '{"test": "value", "number": 123}'
            parsed_result = optimizer._parse_json_result(test_json)
            print(f"   JSONè§£ææµ‹è¯•: {'âœ… æˆåŠŸ' if 'test' in parsed_result else 'âŒ å¤±è´¥'}")
            
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
            return True
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
        finally:
            # æ¸…ç†èµ„æº
            try:
                coordinator.cleanup_system()
                print("âœ… ç³»ç»Ÿèµ„æºæ¸…ç†å®Œæˆ")
            except:
                pass
    
    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    return asyncio.run(run_tests())

if __name__ == "__main__":
    success = test_resume_optimizer()
    sys.exit(0 if success else 1)