#!/usr/bin/env python3
"""
ä¿®å¤æ•°æ®åº“é‡å¤è®°å½•è„šæœ¬
"""

import sqlite3
import logging
from datetime import datetime

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

def fix_job_details_duplicates(db_path: str):
    """ä¿®å¤job_detailsè¡¨çš„é‡å¤è®°å½•"""
    logger = setup_logging()
    
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # 1. ç»Ÿè®¡é‡å¤æƒ…å†µ
            cursor.execute("""
                SELECT COUNT(*) as total_records,
                       COUNT(DISTINCT job_id) as unique_jobs,
                       COUNT(*) - COUNT(DISTINCT job_id) as duplicates
                FROM job_details
            """)
            total, unique, duplicates = cursor.fetchone()
            
            logger.info(f"ä¿®å¤å‰ç»Ÿè®¡:")
            logger.info(f"  æ€»è®°å½•æ•°: {total}")
            logger.info(f"  å”¯ä¸€èŒä½æ•°: {unique}")
            logger.info(f"  é‡å¤è®°å½•æ•°: {duplicates}")
            
            if duplicates == 0:
                logger.info("æ²¡æœ‰å‘ç°é‡å¤è®°å½•ï¼Œæ— éœ€ä¿®å¤")
                return
            
            # 2. æ˜¾ç¤ºé‡å¤è®°å½•è¯¦æƒ…
            cursor.execute("""
                SELECT job_id, COUNT(*) as count
                FROM job_details
                GROUP BY job_id
                HAVING COUNT(*) > 1
                ORDER BY count DESC
            """)
            duplicate_jobs = cursor.fetchall()
            
            logger.info(f"å‘ç° {len(duplicate_jobs)} ä¸ªèŒä½æœ‰é‡å¤è®°å½•:")
            for job_id, count in duplicate_jobs:
                logger.info(f"  {job_id}: {count} æ¡è®°å½•")
            
            # 3. åˆ›å»ºä¸´æ—¶è¡¨ä¿å­˜å»é‡åçš„æ•°æ®
            logger.info("åˆ›å»ºä¸´æ—¶è¡¨...")
            cursor.execute("""
                CREATE TEMPORARY TABLE job_details_temp AS
                SELECT 
                    MIN(id) as id,
                    job_id,
                    salary,
                    location,
                    experience,
                    education,
                    description,
                    requirements,
                    benefits,
                    publish_time,
                    company_scale,
                    industry,
                    keyword,
                    MAX(extracted_at) as extracted_at  -- ä¿ç•™æœ€æ–°çš„æå–æ—¶é—´
                FROM job_details
                GROUP BY job_id
            """)
            
            # 4. åˆ é™¤åŸè¡¨ä¸­çš„æ‰€æœ‰è®°å½•
            logger.info("æ¸…ç©ºåŸè¡¨...")
            cursor.execute("DELETE FROM job_details")
            
            # 5. ä»ä¸´æ—¶è¡¨æ¢å¤å»é‡åçš„æ•°æ®
            logger.info("æ¢å¤å»é‡åçš„æ•°æ®...")
            cursor.execute("""
                INSERT INTO job_details (
                    job_id, salary, location, experience, education,
                    description, requirements, benefits, publish_time,
                    company_scale, industry, keyword, extracted_at
                )
                SELECT 
                    job_id, salary, location, experience, education,
                    description, requirements, benefits, publish_time,
                    company_scale, industry, keyword, extracted_at
                FROM job_details_temp
            """)
            
            # 6. éªŒè¯ä¿®å¤ç»“æœ
            cursor.execute("SELECT COUNT(*) FROM job_details")
            final_count = cursor.fetchone()[0]
            
            cursor.execute("""
                SELECT COUNT(*) - COUNT(DISTINCT job_id) as remaining_duplicates
                FROM job_details
            """)
            remaining_duplicates = cursor.fetchone()[0]
            
            conn.commit()
            
            logger.info(f"ä¿®å¤å®Œæˆ!")
            logger.info(f"  ä¿®å¤åè®°å½•æ•°: {final_count}")
            logger.info(f"  å‰©ä½™é‡å¤æ•°: {remaining_duplicates}")
            logger.info(f"  åˆ é™¤é‡å¤è®°å½•: {duplicates}")
            
            return True
            
    except Exception as e:
        logger.error(f"ä¿®å¤å¤±è´¥: {e}")
        return False

def verify_data_consistency(db_path: str):
    """éªŒè¯æ•°æ®ä¸€è‡´æ€§"""
    logger = setup_logging()
    
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # ç»Ÿè®¡jobsè¡¨
            cursor.execute("SELECT COUNT(*) FROM jobs")
            jobs_count = cursor.fetchone()[0]
            
            # ç»Ÿè®¡job_detailsè¡¨
            cursor.execute("SELECT COUNT(*) FROM job_details")
            details_count = cursor.fetchone()[0]
            
            # ç»Ÿè®¡åŒ¹é…çš„è®°å½•
            cursor.execute("""
                SELECT COUNT(*) 
                FROM jobs j 
                INNER JOIN job_details jd ON j.job_id = jd.job_id
            """)
            matched_count = cursor.fetchone()[0]
            
            # ç»Ÿè®¡å­¤ç«‹è®°å½•
            cursor.execute("""
                SELECT COUNT(*) 
                FROM jobs j 
                LEFT JOIN job_details jd ON j.job_id = jd.job_id 
                WHERE jd.job_id IS NULL
            """)
            orphan_jobs = cursor.fetchone()[0]
            
            cursor.execute("""
                SELECT COUNT(*) 
                FROM job_details jd 
                LEFT JOIN jobs j ON jd.job_id = j.job_id 
                WHERE j.job_id IS NULL
            """)
            orphan_details = cursor.fetchone()[0]
            
            logger.info("=== æ•°æ®ä¸€è‡´æ€§éªŒè¯ ===")
            logger.info(f"Jobsè¡¨è®°å½•æ•°: {jobs_count}")
            logger.info(f"Job_detailsè¡¨è®°å½•æ•°: {details_count}")
            logger.info(f"åŒ¹é…çš„è®°å½•æ•°: {matched_count}")
            logger.info(f"Jobsè¡¨ä¸­å­¤ç«‹è®°å½•: {orphan_jobs}")
            logger.info(f"Job_detailsè¡¨ä¸­å­¤ç«‹è®°å½•: {orphan_details}")
            
            if jobs_count == details_count == matched_count and orphan_jobs == 0 and orphan_details == 0:
                logger.info("âœ… æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡ï¼")
                return True
            else:
                logger.warning("âš ï¸ æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥æœªé€šè¿‡")
                return False
                
    except Exception as e:
        logger.error(f"éªŒè¯å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    db_path = "data/jobs.db"
    
    print("ğŸ”§ å¼€å§‹ä¿®å¤æ•°æ®åº“é‡å¤è®°å½•...")
    
    # ä¿®å¤é‡å¤è®°å½•
    if fix_job_details_duplicates(db_path):
        print("âœ… é‡å¤è®°å½•ä¿®å¤å®Œæˆ")
        
        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        if verify_data_consistency(db_path):
            print("âœ… æ•°æ®åº“ä¿®å¤æˆåŠŸï¼Œæ•°æ®ä¸€è‡´æ€§è‰¯å¥½")
        else:
            print("âš ï¸ æ•°æ®åº“ä¿®å¤å®Œæˆï¼Œä½†ä»å­˜åœ¨ä¸€è‡´æ€§é—®é¢˜")
    else:
        print("âŒ æ•°æ®åº“ä¿®å¤å¤±è´¥")